import streamlit as st
import os
import re
import json
import hashlib
from typing import Optional, Dict, List, Any, Tuple
from collections import Counter
from dotenv import load_dotenv
from file_analyzer import UniversalFileAnalyzer
from dspy_analyzer import EnhancedArchAnalyzer, PROVIDER_CONFIG, get_api_key, get_current_provider
from prompt_processor import load_blocks, load_custom_blocks
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.shared import Pt

# ì¸ì¦ ëª¨ë“ˆ import
try:
    from auth.authentication import is_authenticated, get_current_user, check_page_access
    AUTH_AVAILABLE = True
except ImportError:
    AUTH_AVAILABLE = False
try:
    from geo_data_loader import GeoDataLoader, validate_shapefile_data
    GEO_LOADER_AVAILABLE = True
except ImportError as e:
    GEO_LOADER_AVAILABLE = False
    GeoDataLoader = None
    validate_shapefile_data = None

try:  # pragma: no cover
    import streamlit_folium as st_folium
except ImportError:  # pragma: no cover
    st_folium = None

try:
    import pandas as pd
except ImportError:  # pragma: no cover
    pd = None

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
try:
    load_dotenv()
except UnicodeDecodeError:
    # .env íŒŒì¼ì— ì¸ì½”ë”© ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° ë¬´ì‹œ
    pass

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë„ì‹œ í”„ë¡œì íŠ¸ ë¶„ì„",
    page_icon=None,
    layout="wide"
)

# ì„¸ì…˜ ì´ˆê¸°í™” (ë¡œê·¸ì¸ + ì‘ì—… ë°ì´í„° ë³µì›)
try:
    from auth.session_init import init_page_session
    init_page_session()
except Exception as e:
    print(f"ì„¸ì…˜ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

# ê°•ì œ ë¶ˆëŸ¬ì˜¤ê¸° ì²˜ë¦¬ (ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼ í´ë¦­ ì‹œ)
if st.session_state.get('_force_load_session'):
    try:
        from database.db_manager import execute_query
        import json

        # í”Œë˜ê·¸ ì œê±°
        del st.session_state['_force_load_session']

        # ë¡œê·¸ì¸ í™•ì¸
        if 'pms_current_user' in st.session_state:
            user_id = st.session_state.pms_current_user.get('id')

            if user_id:
                print(f"[ê°•ì œ ë¶ˆëŸ¬ì˜¤ê¸°] ì‚¬ìš©ì ID: {user_id}")

                # DBì—ì„œ ìµœê·¼ ì„¸ì…˜ ì¡°íšŒ
                result = execute_query(
                    """
                    SELECT session_data, created_at FROM analysis_sessions
                    WHERE user_id = ?
                    ORDER BY created_at DESC
                    LIMIT 1
                    """,
                    (user_id,)
                )

                if result and result[0]:
                    session_data = json.loads(result[0]['session_data'])
                    saved_time = result[0]['created_at']

                    print(f"[ê°•ì œ ë¶ˆëŸ¬ì˜¤ê¸°] DBì—ì„œ ë°ì´í„° ë¡œë“œ: {len(session_data)}ê°œ í‚¤")

                    # ë³µì› í”Œë˜ê·¸ ì´ˆê¸°í™” (ê°•ì œ ë³µì›)
                    if 'work_session_restored_global' in st.session_state:
                        del st.session_state['work_session_restored_global']
                    if 'work_session_restoring' in st.session_state:
                        del st.session_state['work_session_restoring']

                    # ì„ì‹œë¡œ ë°ì´í„° ì €ì¥ (ë‹¤ìŒ rerun ë•Œ í‘œì‹œìš©)
                    st.session_state['_loaded_data_info'] = {
                        'project_name': session_data.get('project_name', '(ì—†ìŒ)'),
                        'location': session_data.get('location', '(ì—†ìŒ)'),
                        'saved_time': saved_time,
                        'count': len(session_data)
                    }

                    print(f"[ê°•ì œ ë¶ˆëŸ¬ì˜¤ê¸°] ë³µì› í”Œë˜ê·¸ ì´ˆê¸°í™” ì™„ë£Œ, ìë™ ë³µì› ì‹œì‘")
                    st.rerun()
                else:
                    st.warning("âš ï¸ ì €ì¥ëœ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
                    print("[ê°•ì œ ë¶ˆëŸ¬ì˜¤ê¸°] DBì— ì €ì¥ëœ ì„¸ì…˜ ì—†ìŒ")
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[ê°•ì œ ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜]:\n{error_details}")
        st.error(f"âŒ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")

# ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ
if '_loaded_data_info' in st.session_state:
    info = st.session_state['_loaded_data_info']
    del st.session_state['_loaded_data_info']
    st.success(f"âœ… ì €ì¥ëœ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤! (ì €ì¥ ì‹œê°„: {info['saved_time']})")
    with st.expander("ë¶ˆëŸ¬ì˜¨ ë‚´ìš© í™•ì¸", expanded=True):
        st.write(f"**í”„ë¡œì íŠ¸ëª…**: {info['project_name']}")
        st.write(f"**ìœ„ì¹˜**: {info['location']}")
        st.write(f"**ì´ {info['count']}ê°œ í•­ëª© ë¶ˆëŸ¬ì˜´**")

# ë¡œê·¸ì¸ ì²´í¬
if AUTH_AVAILABLE:
    check_page_access()

# ì œëª©
st.title("ë„ì‹œ í”„ë¡œì íŠ¸ ë¶„ì„")
st.markdown("**ë„ì‹œ í”„ë¡œì íŠ¸ ë¬¸ì„œ ë¶„ì„ (PDF, Excel, CSV, í…ìŠ¤íŠ¸, JSON ì§€ì›)**")

# í˜ì´ì§€ ìƒë‹¨ ì»¨íŠ¸ë¡¤ (ë¦¬ì…‹ ë²„íŠ¼)
col_title, col_reset = st.columns([5, 1])
with col_reset:
    if st.button("ğŸ—‘ï¸ í˜ì´ì§€ ì´ˆê¸°í™”", use_container_width=True, help="ì´ í˜ì´ì§€ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"):
        # Document Analysis í˜ì´ì§€ ê´€ë ¨ ëª¨ë“  ë°ì´í„° ì´ˆê¸°í™”
        keys_to_reset = [
            'project_name', 'location', 'latitude', 'longitude',
            'project_goals', 'additional_info', 'pdf_text', 'pdf_uploaded',
            'uploaded_file', 'file_type', 'file_analysis',
            'selected_blocks', 'analysis_results', 'cot_results',
            'cot_session', 'cot_plan', 'cot_current_index',
            'cot_running_block', 'cot_progress_messages', 'cot_feedback_inputs',
            'skipped_blocks', 'cot_citations', 'cot_history', 'cot_analyzer',
            'preprocessed_text', 'preprocessed_summary', 'preprocessing_meta',
            'reference_documents', 'reference_combined_text', 'reference_signature',
            'block_spatial_data', 'block_spatial_selection',
            'document_summary'
        ]
        for key in keys_to_reset:
            if key in st.session_state:
                del st.session_state[key]

        # ë³µì› í‚¤ëŠ” Trueë¡œ ì„¤ì • (rerun í›„ ë³µì› ë°©ì§€)
        st.session_state['work_session_restored_global'] = True
        if 'work_session_restoring' in st.session_state:
            del st.session_state['work_session_restoring']

        # DB ë° GitHub ë°±ì—… ì™„ì „ ì‚­ì œ
        try:
            from database.db_manager import execute_query
            if 'pms_current_user' in st.session_state:
                user_id = st.session_state.pms_current_user.get('id')
                if user_id:
                    # DBì—ì„œ ì„¸ì…˜ ë°ì´í„° ì‚­ì œ
                    execute_query(
                        "DELETE FROM analysis_sessions WHERE user_id = ?",
                        (user_id,),
                        commit=True
                    )
                    # analysis_progressë„ ì‚­ì œ
                    execute_query(
                        "DELETE FROM analysis_progress WHERE user_id = ?",
                        (user_id,),
                        commit=True
                    )
                    print(f"[ì´ˆê¸°í™”] DBì—ì„œ ì‚¬ìš©ì({user_id}) ë°ì´í„° ì™„ì „ ì‚­ì œ ì™„ë£Œ")

                    # GitHub ë°±ì—…ë„ ì‚­ì œ
                    try:
                        from github_storage import delete_from_github, is_github_storage_available
                        if is_github_storage_available():
                            # personal_numberë¥¼ í´ë” ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
                            personal_number = user.get('personal_number')
                            if personal_number:
                                delete_from_github(personal_number, "session")
                                print(f"[ì´ˆê¸°í™”] GitHub ë°±ì—… ì‚­ì œ ì™„ë£Œ (user: {personal_number})")
                    except Exception as gh_e:
                        print(f"[ì´ˆê¸°í™”] GitHub ë°±ì—… ì‚­ì œ ì˜¤ë¥˜ (ë¬´ì‹œ): {gh_e}")
        except Exception as e:
            print(f"[ì´ˆê¸°í™”] DB ì‚­ì œ ì˜¤ë¥˜: {e}")

        print(f"[ì´ˆê¸°í™”] {len(keys_to_reset)}ê°œ í‚¤ ì‚­ì œ ì™„ë£Œ (DB + GitHub í¬í•¨)")

        st.success("âœ… í˜ì´ì§€ê°€ ì™„ì „íˆ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()

st.markdown("---")

# ì‚¬ìš©ì ì¸ì¦ ìƒíƒœ í‘œì‹œ (ì‚¬ì´ë“œë°”)
if AUTH_AVAILABLE:
    with st.sidebar:
        if is_authenticated():
            user = get_current_user()
            st.success(f"ë¡œê·¸ì¸: {user.get('display_name', user.get('personal_number'))}")
        else:
            st.warning("ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤")
            st.info("ì‚¬ì´ë“œë°”ì—ì„œ 'ë¡œê·¸ì¸' í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”.")
        st.markdown("---")

# Session state ì´ˆê¸°í™” (ìë™ ë³µì› ì—†ì´ ë¹ˆ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”)
if 'project_name' not in st.session_state:
    st.session_state.project_name = ""
    print("[ì´ˆê¸°í™”] project_nameì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”")
else:
    print(f"[ì´ˆê¸°í™”] project_name ì´ë¯¸ ì¡´ì¬: '{st.session_state.project_name}'")
if 'location' not in st.session_state:
    st.session_state.location = ""
if 'latitude' not in st.session_state:
    st.session_state.latitude = ""
if 'longitude' not in st.session_state:
    st.session_state.longitude = ""
if 'project_goals' not in st.session_state:
    st.session_state.project_goals = ""
if 'additional_info' not in st.session_state:
    st.session_state.additional_info = ""
if 'uploaded_file' not in st.session_state:
    st.session_state.uploaded_file = None
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = {}

if 'selected_blocks' not in st.session_state:
    st.session_state.selected_blocks = []
if 'pdf_text' not in st.session_state:
    st.session_state.pdf_text = ""
if 'pdf_uploaded' not in st.session_state:
    st.session_state.pdf_uploaded = False
# ê³µê°„ ë°ì´í„° ì´ˆê¸°í™” (Mapping í˜ì´ì§€ì—ì„œ ì—…ë¡œë“œëœ Shapefile ì €ì¥ìš©)
if 'geo_layers' not in st.session_state:
    st.session_state.geo_layers = {}
if 'uploaded_gdf' not in st.session_state:
    st.session_state.uploaded_gdf = None
if 'uploaded_layer_info' not in st.session_state:
    st.session_state.uploaded_layer_info = None
if 'preprocessed_summary' not in st.session_state:
    st.session_state.preprocessed_summary = ""
if 'preprocessed_text' not in st.session_state:
    st.session_state.preprocessed_text = ""
if 'preprocessing_meta' not in st.session_state:
    st.session_state.preprocessing_meta = {}
if 'preprocessing_options' not in st.session_state:
    st.session_state.preprocessing_options = {
        "clean_whitespace": True,
        "collapse_blank_lines": True,
        "limit_chars": 6000,
        "include_keywords": True,
        "keyword_count": 12,
        "include_numeric_sentences": True,
        "numeric_sentence_count": 5
    }
if 'use_preprocessed_text' not in st.session_state:
    st.session_state.use_preprocessed_text = False
if 'llm_temperature' not in st.session_state:
    st.session_state.llm_temperature = 0.2
if 'llm_max_tokens' not in st.session_state:
    st.session_state.llm_max_tokens = 16000
if 'cot_session' not in st.session_state:
    st.session_state.cot_session = None
if 'cot_plan' not in st.session_state:
    st.session_state.cot_plan = []
if 'cot_current_index' not in st.session_state:
    st.session_state.cot_current_index = 0
if 'llm_provider' not in st.session_state:
    st.session_state.llm_provider = 'gemini_25flash'
if 'cot_results' not in st.session_state:
    st.session_state.cot_results = {}
if 'cot_citations' not in st.session_state:
    st.session_state.cot_citations = {}
if 'cot_progress_messages' not in st.session_state:
    st.session_state.cot_progress_messages = []
if 'cot_history' not in st.session_state:
    st.session_state.cot_history = []
if 'cot_analyzer' not in st.session_state:
    st.session_state.cot_analyzer = None
if 'cot_running_block' not in st.session_state:
    st.session_state.cot_running_block = None
if 'cot_feedback_inputs' not in st.session_state:
    st.session_state.cot_feedback_inputs = {}
if 'reference_documents' not in st.session_state:
    st.session_state.reference_documents = []
if 'reference_combined_text' not in st.session_state:
    st.session_state.reference_combined_text = ""
if 'reference_signature' not in st.session_state:
    st.session_state.reference_signature = None
if 'document_summary' not in st.session_state:
    st.session_state.document_summary = None

DEFAULT_FIXED_PROGRAM = {
    "phase1_program_intro": "",
    "phase1_program_education": "",
    "phase1_program_sports": "",
    "phase1_program_convention": "",
    "phase1_program_wellness": "",
    "phase1_program_other": ""
}

for key, value in DEFAULT_FIXED_PROGRAM.items():
    if key not in st.session_state:
        st.session_state[key] = value

def build_fixed_program_markdown() -> str:
    return "\n".join([
        "## ê³ ì • í”„ë¡œê·¸ë¨ ì‚¬ì–‘ (ì‚¼ì²™ ìŠ¤í¬ì¸ ì•„ì¹´ë°ë¯¸)",
        "",
        st.session_state.get("phase1_program_intro", "").strip(),
        "",
        "### êµìœ¡ ì‹œì„¤",
        st.session_state.get("phase1_program_education", "").strip(),
        "",
        "### ìŠ¤í¬ì¸  ì§€ì›ì‹œì„¤",
        st.session_state.get("phase1_program_sports", "").strip(),
        "",
        "### ì»¨ë²¤ì…˜ ì‹œì„¤",
        st.session_state.get("phase1_program_convention", "").strip(),
        "",
        "### ì¬í™œ/ì›°ë‹ˆìŠ¤",
        st.session_state.get("phase1_program_wellness", "").strip(),
        "",
        "### ê¸°íƒ€ ì‹œì„¤",
        st.session_state.get("phase1_program_other", "").strip()
    ])

def save_analysis_result(block_id, analysis_result, project_info=None):
    """ê°œë³„ ë¸”ë¡ ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ + GitHub ë°±ì—…"""
    from datetime import datetime
    import json
    import os

    # 1. ë¡œì»¬ ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
    analysis_folder = "analysis_results"
    os.makedirs(analysis_folder, exist_ok=True)

    # íŒŒì¼ëª…: block_{block_id}_{timestamp}.json
    filename = f"block_{block_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    filepath = os.path.join(analysis_folder, filename)

    block_record = {
        "block_id": block_id,
        "analysis_result": analysis_result,
        "saved_timestamp": datetime.now().isoformat(),
        "project_info": project_info or {
            "project_name": st.session_state.get('project_name', ''),
            "location": st.session_state.get('location', '')
        }
    }

    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(block_record, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ ({block_id}): {e}")
        return None

    # 2. GitHub ë°±ì—… (Streamlit Cloudìš©)
    try:
        from github_storage import save_analysis_to_github, is_github_storage_available
        if is_github_storage_available():
            user_id = st.session_state.get('pms_current_user', {}).get('id', 'anonymous')
            if isinstance(user_id, int):
                user_id = str(user_id)
            save_analysis_to_github(user_id, block_id, analysis_result, block_record.get('project_info'))
    except Exception as e:
        print(f"[GitHub ë°±ì—…] ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

    return filepath

def load_saved_analysis_results():
    """analysis_results í´ë” + GitHubì—ì„œ ì €ì¥ëœ ëª¨ë“  ë¸”ë¡ ê²°ê³¼ë¥¼ ë¡œë“œ"""
    import json
    import os
    import glob
    from datetime import datetime

    results = {}

    # 1. ë¡œì»¬ íŒŒì¼ì—ì„œ ë¨¼ì € ë¡œë“œ
    analysis_folder = "analysis_results"
    if os.path.exists(analysis_folder):
        pattern = os.path.join(analysis_folder, "block_*.json")
        files = glob.glob(pattern)

        block_latest = {}
        for filepath in files:
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    block_id = data.get('block_id')
                    if block_id:
                        saved_time = datetime.fromisoformat(data.get('saved_timestamp', ''))
                        if block_id not in block_latest or saved_time > block_latest[block_id]['time']:
                            block_latest[block_id] = {
                                'result': data.get('analysis_result', ''),
                                'time': saved_time,
                                'file': filepath
                            }
            except Exception:
                continue

        results = {block_id: info['result'] for block_id, info in block_latest.items()}

    # 2. ë¡œì»¬ì— ì—†ìœ¼ë©´ GitHubì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (Streamlit Cloud ì¬ì‹œì‘ í›„)
    if not results:
        try:
            from github_storage import load_all_analysis_from_github, is_github_storage_available
            if is_github_storage_available():
                user_id = st.session_state.get('pms_current_user', {}).get('id', 'anonymous')
                if isinstance(user_id, int):
                    user_id = str(user_id)
                github_results = load_all_analysis_from_github(user_id)
                if github_results:
                    results = github_results
                    print(f"[GitHub] {len(results)}ê°œ ë¶„ì„ ê²°ê³¼ ë³µì›ë¨")
        except Exception as e:
            print(f"[GitHub ë¶ˆëŸ¬ì˜¤ê¸°] ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

    return results

def get_cot_analyzer() -> Optional[EnhancedArchAnalyzer]:
    """CoT Analyzerë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤. Provider ë³€ê²½ ì‹œ ì¬ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        current_provider = get_current_provider()
        
        # Providerê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ analyzerê°€ ì—†ê±°ë‚˜ Noneì´ë©´ ì¬ìƒì„±
        last_provider = st.session_state.get('_last_analyzer_provider')
        cot_analyzer_exists = st.session_state.get('cot_analyzer') is not None
        if (last_provider != current_provider) or (not cot_analyzer_exists):
            # ê¸°ì¡´ analyzer ì œê±°
            if 'cot_analyzer' in st.session_state:
                del st.session_state.cot_analyzer
            # ìƒˆ analyzer ìƒì„± (ì˜ˆì™¸ ì²˜ë¦¬)
            try:
                analyzer = EnhancedArchAnalyzer()
                # ì´ˆê¸°í™” ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ í™•ì¸
                if hasattr(analyzer, '_init_error'):
                    init_error = analyzer._init_error
                    st.error(f"ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
                    st.info(" **í•´ê²° ë°©ë²•**:")
                    provider_config = PROVIDER_CONFIG.get(current_provider, {})
                    api_key_env = provider_config.get('api_key_env', '')
                    display_name = provider_config.get('display_name', current_provider)
                    
                    if current_provider == 'gemini':
                        st.info("1. Google AI Studio API í‚¤ í™•ì¸:")
                        st.code(f"   .streamlit/secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— {api_key_env} ì„¤ì •", language=None)
                        st.info("2. API í‚¤ í˜•ì‹ í™•ì¸: AIza...ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ìì—´")
                        st.info("3. Google AI Studioì—ì„œ API í‚¤ ìƒì„±: https://aistudio.google.com/app/apikey")
                    else:
                        st.info(f"1. {display_name} API í‚¤ í™•ì¸:")
                        st.code(f"   .streamlit/secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— {api_key_env} ì„¤ì •", language=None)
                        st.info("2. API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸")
                        st.info("3. Streamlit ì•±ì„ ì¬ì‹œì‘í•´ë³´ì„¸ìš”")
                    return None
                
                st.session_state.cot_analyzer = analyzer
                st.session_state._last_analyzer_provider = current_provider
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                st.error(f"ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´", expanded=False):
                    st.code(error_detail, language='python')
                st.info(" **í•´ê²° ë°©ë²•**:")
                provider_config = PROVIDER_CONFIG.get(current_provider, {})
                api_key_env = provider_config.get('api_key_env', '')
                display_name = provider_config.get('display_name', current_provider)
                
                if current_provider == 'gemini':
                    st.info("1. Google AI Studio API í‚¤ í™•ì¸:")
                    st.code(f"   .streamlit/secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— {api_key_env} ì„¤ì •", language=None)
                    st.info("2. API í‚¤ í˜•ì‹ í™•ì¸: AIza...ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ìì—´")
                    st.info("3. Google AI Studioì—ì„œ API í‚¤ ìƒì„±: https://aistudio.google.com/app/apikey")
                else:
                    st.info(f"1. {display_name} API í‚¤ í™•ì¸:")
                    st.code(f"   .streamlit/secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— {api_key_env} ì„¤ì •", language=None)
                    st.info("2. API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸")
                    st.info("3. Streamlit ì•±ì„ ì¬ì‹œì‘í•´ë³´ì„¸ìš”")
                return None
        else:
            analyzer = st.session_state.cot_analyzer
        
        # analyzerê°€ Noneì¸ì§€ í™•ì¸
        if analyzer is None:
            st.error("ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
            return None
        
        # analyzerì— ì´ˆê¸°í™” ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ í™•ì¸
        if hasattr(analyzer, '_init_error'):
            st.error(f"ë¶„ì„ê¸° ì´ˆê¸°í™” ì˜¤ë¥˜: {analyzer._init_error}")
            st.info(" ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ê³  API í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            return None
        
        return analyzer
    except Exception as e:
        st.error(f"ë¶„ì„ê¸° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return None

def parse_result_into_sections(text: str) -> List[Dict[str, str]]:
    """
    ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì„¹ì…˜ë³„ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
    
    Args:
        text: ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
        
    Returns:
        ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸ (ê° ì„¹ì…˜ì€ {'title': str, 'content': str} í˜•íƒœ)
    """
    if not text:
        return [{'title': '', 'content': text}]
    
    sections = []
    lines = text.split('\n')
    current_section = {'title': '', 'content': ''}
    
    # ì„¹ì…˜ í—¤ë” íŒ¨í„´ (##, ###, #### ë“±)
    section_pattern = re.compile(r'^(#{1,6})\s+(.+)$')
    
    for line in lines:
        match = section_pattern.match(line.strip())
        if match:
            # ì´ì „ ì„¹ì…˜ ì €ì¥
            if current_section['content'].strip():
                sections.append(current_section)
            
            # ìƒˆ ì„¹ì…˜ ì‹œì‘
            level = len(match.group(1))
            title = match.group(2).strip()
            # ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ì ì œê±° (íƒ­ ì´ë¦„ì— ì‚¬ìš©í•˜ê¸° ìœ„í•´)
            clean_title = re.sub(r'[\[\]ì—°ë™ëŒ€ê¸°ì§„í–‰ì™„ë£Œë¸”ë¡ê²°ê³¼]', '', title).strip()
            current_section = {'title': clean_title, 'content': line + '\n'}
        else:
            current_section['content'] += line + '\n'
    
    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
    if current_section['content'].strip():
        sections.append(current_section)
    
    # ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ìœ¼ë¡œ
    if not sections:
        return [{'title': '', 'content': text}]
    
    return sections

def reset_step_analysis_state(preserve_existing_results: bool = False) -> None:
    """
    ë‹¨ê³„ë³„ ë¶„ì„ ì„¸ì…˜ ìƒíƒœë¥¼ ì™„ì „íˆ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    Args:
        preserve_existing_results: Trueì´ë©´ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
    """
    # ë¶„ì„ê¸° ë‚´ë¶€ ìƒíƒœë„ ì™„ì „íˆ ì´ˆê¸°í™”
    try:
        EnhancedArchAnalyzer.reset_lm()
    except Exception:
        pass

    # LiteLLM ìºì‹œ ì´ˆê¸°í™” (ì´ì „ ë¶„ì„ ê²°ê³¼ê°€ ìºì‹œì—ì„œ ë°˜í™˜ë˜ëŠ” ê²ƒ ë°©ì§€)
    try:
        import litellm
        if hasattr(litellm, 'cache') and litellm.cache is not None:
            litellm.cache = None
        if hasattr(litellm, '_async_client'):
            litellm._async_client = None
    except Exception:
        pass

    # DSPy ìºì‹œ ë° ìƒíƒœ ì´ˆê¸°í™”
    try:
        import dspy
        # DSPy LM ì´ˆê¸°í™” ìƒíƒœ ë¦¬ì…‹
        EnhancedArchAnalyzer._lm_initialized = False
        EnhancedArchAnalyzer._last_provider = None
        # DSPy ë‚´ë¶€ ìºì‹œ ì´ˆê¸°í™” ì‹œë„
        if hasattr(dspy, 'cache') and dspy.cache is not None:
            if hasattr(dspy.cache, 'clear'):
                dspy.cache.clear()
        # DSPy settings ë¦¬ì…‹
        if hasattr(dspy, 'settings'):
            try:
                dspy.settings.configure(lm=None)
            except Exception:
                pass
    except Exception:
        pass

    # ëª¨ë“  ì„¸ì…˜ ìƒíƒœë¥¼ ì™„ì „íˆ ì´ˆê¸°í™”
    st.session_state.cot_session = None
    st.session_state.cot_plan = []
    st.session_state.cot_current_index = 0
    st.session_state.cot_results = {}
    st.session_state.cot_progress_messages = []
    st.session_state.cot_running_block = None
    st.session_state.skipped_blocks = []  # ê±´ë„ˆë›´ ë¸”ë¡ ëª©ë¡ ì´ˆê¸°í™”
    
    # analyzerë¥¼ ì™„ì „íˆ ì‚­ì œí•˜ì—¬ ì¬ìƒì„±ë˜ë„ë¡ í•¨
    st.session_state.pop('cot_analyzer', None)
    st.session_state.pop('_last_analyzer_provider', None)
    
    if not preserve_existing_results:
        # ëª¨ë“  ë¶„ì„ ê²°ê³¼ ì™„ì „íˆ ì´ˆê¸°í™”
        st.session_state.analysis_results = {}
        st.session_state.cot_citations = {}
        st.session_state.cot_history = []
        st.session_state.cot_feedback_inputs = {}
        st.session_state.document_summary = None  # ë¬¸ì„œ ìš”ì•½ë„ ì´ˆê¸°í™”

        # Phase 1 ê´€ë ¨ ê°œë³„ ë¸”ë¡ ê²°ê³¼ ì´ˆê¸°í™” (ì œê±°ëœ ë¸”ë¡ë“¤)
        st.session_state.pop('phase1_requirements_cot_history', None)
        st.session_state.pop('phase1_3_requirements_text', None)
        st.session_state.pop('phase1_3_requirements_loaded', None)
        st.session_state.pop('phase1_3_selected_site', None)
        st.session_state.pop('phase1_3_selected_site_name', None)

def reset_all_state() -> None:
    """
    ëª¨ë“  ì„¸ì…˜ ìƒíƒœë¥¼ ì™„ì „íˆ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    í”„ë¡œì íŠ¸ ì •ë³´, íŒŒì¼, ë¶„ì„ ê²°ê³¼, CoT ìƒíƒœ, ê³µê°„ ë°ì´í„° ë“± ëª¨ë“  ê²ƒì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    # í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ ì´ˆê¸°í™”
    st.session_state.project_name = ""
    st.session_state.location = ""
    st.session_state.project_goals = ""
    st.session_state.additional_info = ""
    
    # íŒŒì¼ ê´€ë ¨ ì´ˆê¸°í™”
    st.session_state.uploaded_file = None
    st.session_state.pdf_text = ""
    st.session_state.pdf_uploaded = False
    
    # ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
    st.session_state.analysis_results = {}
    st.session_state.selected_blocks = []
    
    # CoT ê´€ë ¨ ì´ˆê¸°í™”
    st.session_state.cot_session = None
    st.session_state.cot_plan = []
    st.session_state.cot_current_index = 0
    st.session_state.cot_results = {}
    st.session_state.cot_progress_messages = []
    st.session_state.cot_analyzer = None
    st.session_state.cot_running_block = None
    st.session_state.skipped_blocks = []  # ê±´ë„ˆë›´ ë¸”ë¡ ëª©ë¡ ì´ˆê¸°í™”
    st.session_state.cot_history = []
    st.session_state.cot_feedback_inputs = {}
    
    # ì „ì²˜ë¦¬ ê´€ë ¨ ì´ˆê¸°í™”
    st.session_state.preprocessed_summary = ""
    st.session_state.preprocessed_text = ""
    st.session_state.preprocessing_meta = {}
    st.session_state.use_preprocessed_text = False
    st.session_state.preprocessing_options = {
        "clean_whitespace": True,
        "collapse_blank_lines": True,
        "limit_chars": 6000,
        "include_keywords": True,
        "keyword_count": 12,
        "include_numeric_sentences": True,
        "numeric_sentence_count": 5
    }
    
    # ê³µê°„ ë°ì´í„° ì´ˆê¸°í™”
    st.session_state.geo_layers = {}
    st.session_state.uploaded_gdf = None
    st.session_state.uploaded_layer_info = None
    
    # ì°¸ê³  ë¬¸ì„œ ì´ˆê¸°í™”
    st.session_state.reference_documents = []
    st.session_state.reference_combined_text = ""
    st.session_state.reference_signature = None
    
    # Phase 1 ê´€ë ¨ ê°œë³„ ë¸”ë¡ ê²°ê³¼ ì´ˆê¸°í™” (ì œê±°ëœ ë¸”ë¡ë“¤)
    phase1_keys = [
        'phase1_requirements_cot_history',
        'phase1_3_requirements_text',
        'phase1_3_requirements_loaded',
        'phase1_3_selected_site',
        'phase1_3_selected_site_name',
        'phase1_felo_data',
        'phase1_candidate_geo_layers',
        'phase1_candidate_sites',
        'phase1_candidate_filtered',
        'phase1_selected_sites',
        'phase1_candidate_felo_text',
        'phase1_candidate_felo_sections',
        'phase1_parse_result',
    ]
    for key in phase1_keys:
        st.session_state.pop(key, None)
    
    # ê³ ì • í”„ë¡œê·¸ë¨ ë°ì´í„° ì´ˆê¸°í™”
    for key in DEFAULT_FIXED_PROGRAM.keys():
        st.session_state[key] = ""

def ensure_preprocessing_options_structure(options: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    """ì „ì²˜ë¦¬ ì˜µì…˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ê¸°ë³¸ê°’ê³¼ ë³‘í•©í•©ë‹ˆë‹¤."""
    defaults: Dict[str, Any] = {
        "clean_whitespace": True,
        "collapse_blank_lines": True,
        "limit_chars": 6000,
        "include_keywords": True,
        "keyword_count": 12,
        "include_numeric_sentences": True,
        "numeric_sentence_count": 5,
        "include_intro_snippet": True,
        "intro_snippet_chars": 500
    }
    merged = defaults.copy()
    if options:
        for key, value in options.items():
            if key in defaults and value is not None:
                merged[key] = value
    return merged

def preprocess_analysis_text(raw_text: str, options: Dict[str, Any]) -> Tuple[str, str, Dict[str, Any]]:
    """
    ë¶„ì„ ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        raw_text: ì›ë³¸ í…ìŠ¤íŠ¸
        options: ì „ì²˜ë¦¬ ì˜µì…˜

    Returns:
        (ì •ì œëœ í…ìŠ¤íŠ¸, ìš”ì•½ ë¬¸ìì—´, í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬)
    """
    if not raw_text:
        return "", "", {}
    
    import re
    
    opts = ensure_preprocessing_options_structure(options)
    text = raw_text.replace("\r\n", "\n").replace("\r", "\n")
    
    if opts.get("clean_whitespace", True):
        text = re.sub(r"[ \t]+", " ", text)
    
    if opts.get("collapse_blank_lines", True):
        text = re.sub(r"\n{3,}", "\n\n", text)
    
    cleaned_text = text.strip()
    limit_chars = opts.get("limit_chars")
    if isinstance(limit_chars, int) and limit_chars > 0:
        cleaned_text = cleaned_text[:limit_chars]
    
    # ë‹¨ì–´ ë° í†µê³„ ê³„ì‚°
    word_pattern = re.compile(r"[A-Za-zê°€-í£0-9]{2,}")
    original_words = word_pattern.findall(raw_text)
    processed_words = word_pattern.findall(cleaned_text)
    
    # í‚¤ì›Œë“œ ê³„ì‚°
    keyword_summary = ""
    keyword_total = 0
    if opts.get("include_keywords", True) and processed_words:
        keywords = Counter(word.lower() for word in processed_words)
        keyword_count = max(1, int(opts.get("keyword_count", 10)))
        common_keywords = keywords.most_common(keyword_count)
        if common_keywords:
            keyword_total = len(common_keywords)
            keyword_summary = ", ".join(f"{word}({count})" for word, count in common_keywords)
    
    # ì£¼ìš” ìˆ˜ì¹˜ ë¬¸ì¥ ì¶”ì¶œ
    numeric_summary_lines: List[str] = []
    if opts.get("include_numeric_sentences", True):
        sentences = re.split(r"(?<=[.!?])\s+|\n+", cleaned_text)
        numeric_sentences = [s.strip() for s in sentences if any(ch.isdigit() for ch in s)]
        numeric_limit = max(1, int(opts.get("numeric_sentence_count", 5)))
        for sentence in numeric_sentences[:numeric_limit]:
            numeric_summary_lines.append(f"- {sentence}")
    
    intro_snippet = ""
    if opts.get("include_intro_snippet", True) and cleaned_text:
        intro_chars = max(100, int(opts.get("intro_snippet_chars", 500)))
        intro_snippet = cleaned_text[:intro_chars]
    
    summary_sections: List[str] = []
    if intro_snippet:
        summary_sections.append(f"**ìš”ì•½ ìŠ¤ë‹ˆí«:**\n{intro_snippet}...")
    if keyword_summary:
        summary_sections.append(f"**í•µì‹¬ í‚¤ì›Œë“œ Top {keyword_total}:** {keyword_summary}")
    if numeric_summary_lines:
        summary_sections.append("**ì£¼ìš” ìˆ˜ì¹˜ ë¬¸ì¥:**\n" + "\n".join(numeric_summary_lines))
    
    summary_text = "\n\n".join(summary_sections).strip()
    
    stats = {
        "original_chars": len(raw_text),
        "processed_chars": len(cleaned_text),
        "original_words": len(original_words),
        "processed_words": len(processed_words),
        "keyword_summary": keyword_summary,
        "keyword_total": keyword_total
    }
    
    return cleaned_text, summary_text, stats

def get_phase1_candidate_sites():
    return st.session_state.get('phase1_candidate_sites', [])

def _safe_numeric(value, multiplier: float = 1.0):
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value) * multiplier
    text = str(value).strip()
    if not text:
        return None
    text_clean = re.sub(r'[^0-9.\-]', '', text.replace(',', ''))
    if not text_clean:
        return None
    try:
        return float(text_clean) * multiplier
    except ValueError:
        return None

def _parse_area_to_m2(value):
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value)
    text = str(value).strip()
    if not text:
        return None
    if "ha" in text.lower():
        base = _safe_numeric(text)
        return base * 10000 if base is not None else None
    if "ë§Œ" in text and "í‰" in text:
        match = re.search(r'(\d+)', text.replace(',', ''))
        if match:
            return int(match.group(1)) * 10000 * 3.3058
    if "í‰" in text:
        base = _safe_numeric(text)
        return base * 3.3058 if base is not None else None
    return _safe_numeric(text)

def _normalize_candidate_entry(entry):
    if not isinstance(entry, dict):
        return None
    name = entry.get("name") or entry.get("site_name") or entry.get("candidate_name")
    if not name:
        return None
    lat = _safe_numeric(entry.get("lat") or entry.get("latitude"))
    lon = _safe_numeric(entry.get("lon") or entry.get("lng") or entry.get("longitude"))
    area_m2 = _parse_area_to_m2(entry.get("area_m2") or entry.get("site_area") or entry.get("area_sq_m"))
    slope = _safe_numeric(entry.get("slope_percent") or entry.get("slope"))
    road_distance = _safe_numeric(entry.get("road_distance_m") or entry.get("road_distance"))
    facilities = entry.get("existing_facilities") or entry.get("nearby_facilities")
    try:
        facilities = int(facilities)
    except (TypeError, ValueError):
        facilities = 0
    expansion = entry.get("expansion_potential") or entry.get("expandability") or ""
    notes = entry.get("notes") or entry.get("summary") or entry.get("comment") or ""
    land_use = entry.get("land_use") or entry.get("zoning") or ""
    candidate = {
        "name": name,
        "lat": lat,
        "lon": lon,
        "area_m2": area_m2,
        "slope_percent": slope,
        "land_use": land_use,
        "road_distance_m": road_distance,
        "existing_facilities": facilities,
        "expansion_potential": expansion,
        "notes": notes
    }
    essential_fields = ["lat", "lon", "area_m2"]
    if any(candidate[field] is None for field in essential_fields):
        return None
    return candidate

def parse_candidate_sites_from_text(raw_text: str):
    if not raw_text:
        return []
    possible_texts = []
    json_pattern = re.compile(r'```json\s*(\[\s*\{.*?\}\s*\])\s*```', re.DOTALL)
    match = json_pattern.search(raw_text)
    if match:
        possible_texts.append(match.group(1))
    bracket_match = re.search(r'(\[\s*\{.*\}\s*\])', raw_text, re.DOTALL)
    if bracket_match:
        possible_texts.append(bracket_match.group(1))
    possible_texts.append(raw_text)
    for text in possible_texts:
        try:
            data = json.loads(text)
            if isinstance(data, list):
                normalized = []
                for entry in data:
                    normalized_entry = _normalize_candidate_entry(entry)
                    if normalized_entry:
                        normalized.append(normalized_entry)
                if normalized:
                    return normalized
        except Exception:
            continue
    return []

def parse_felo_candidate_blocks(raw_text: str):
    """Felo í˜•ì‹ì˜ í›„ë³´ì§€ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ íŒŒì‹±í•˜ì—¬ í›„ë³´ì§€ ëª©ë¡ìœ¼ë¡œ ë³€í™˜"""
    if not raw_text:
        return []

    # ë°©ë²• 1: ì •ê·œì‹ìœ¼ë¡œ "í›„ë³´ì§€ X - " íŒ¨í„´ ì°¾ê¸° (ê°€ì¥ ì•ˆì •ì )
    candidate_pattern = r'í›„ë³´ì§€\s*([A-Zê°€-í£]+)\s*[-â€“â€”]\s*(.+?)(?=(?:ğŸ…°ï¸|ğŸ…±ï¸|ğŸ…²ï¸|ğŸ…³ï¸|ğŸ…´ï¸|ğŸ…µï¸|ğŸ…¶ï¸|ğŸ…·ï¸|ğŸ…¸ï¸|ğŸ…¹ï¸|í›„ë³´ì§€\s*[A-Zê°€-í£]+\s*[-â€“â€”])|$)'
    matches = list(re.finditer(candidate_pattern, raw_text, re.DOTALL))
    
    sections = []
    if matches:
        for match in matches:
            candidate_id = match.group(1).strip()  # A, B, C, D, E ë“±
            content = match.group(2).strip()  # ë‚˜ë¨¸ì§€ ì „ì²´ ë‚´ìš©
            
            sections.append({
                "id": candidate_id,
                "header": f"í›„ë³´ì§€ {candidate_id}",
                "content": [line.strip() for line in content.splitlines() if line.strip()]
            })

    parsed_candidates = []
    for section in sections:
        candidate_id = section.get("id", "")
        header = section["header"]
        content_list = section["content"]
        content_text = "\n".join(content_list)

        def extract_numeric_value(pattern, text, average=False, unit_multiplier=1.0):
            match = re.search(pattern, text)
            if not match:
                return None
            numbers = re.findall(r'[\d.,]+', match.group(0))
            if not numbers:
                return None
            values = []
            for num in numbers:
                try:
                    values.append(float(num.replace(',', '')))
                except ValueError:
                    continue
            if not values:
                return None
            if average and len(values) >= 2:
                return sum(values) / len(values)
            return values[0] * unit_multiplier

        area_line = next((line for line in content_list if "ë©´ì " in line), "")
        slope_line = next((line for line in content_list if "ê²½ì‚¬" in line), "")
        ic_line = next((line for line in content_list if "IC" in line or "IC ê±°ë¦¬" in line), "")
        facility_line = next((line for line in content_list if "í•µì‹¬ ì²´ìœ¡ì‹œì„¤" in line or "ì²´ìœ¡ì‹œì„¤" in line), "")
        constraint_line = next((line for line in content_list if line.startswith("ì œì•½")), "")
        total_score_line = next((line for line in content_list if "ì´ì " in line), "")
        summary_lines = [line for line in content_list if line.startswith("ìš”ì•½")]

        area_m2 = extract_numeric_value(r"ë©´ì [^0-9]*([\d,\.]+)", area_line)
        slope_percent = extract_numeric_value(r"ê²½ì‚¬[^0-9]*([\d,\.]+(?:\s*-\s*[\d,\.]+)?)", slope_line, average=True)
        road_distance_m = extract_numeric_value(r"(IC ê±°ë¦¬|IC)[^0-9]*([\d,\.]+)", ic_line)
        facility_distance_m = extract_numeric_value(r"í•µì‹¬ ì²´ìœ¡ì‹œì„¤[^0-9]*([\d,\.]+)", facility_line)
        score_value = extract_numeric_value(r"ì´ì [^0-9]*([\d,\.]+)", total_score_line)
        confidence_match = re.search(r"ë°ì´í„°\s*ì‹ ë¢°ë„[^0-9]*([\d\.]+)/([\d\.]+)", total_score_line)
        data_confidence = None
        if confidence_match:
            try:
                numerator = float(confidence_match.group(1))
                denominator = float(confidence_match.group(2))
                if denominator > 0:
                    data_confidence = numerator / denominator
            except ValueError:
                data_confidence = None

        land_use = ""
        land_use_match = re.search(r"ë©´ì [^()]*\((.*?)\)", area_line)
        if land_use_match:
            land_use = land_use_match.group(1)

        summary_text = ""
        if summary_lines:
            summary_text = " ".join(summary_lines)
        else:
            summary_text = constraint_line

        notes = []
        if constraint_line:
            notes.append(constraint_line)
        if summary_text:
            notes.append(summary_text)
        if facility_line:
            notes.append(facility_line)

        # í›„ë³´ì§€ ì´ë¦„ ìƒì„± (ì˜ˆ: "êµë™Â·ì„±ë‚¨ë™ ì¼ì›")
        location_name = ""
        first_line = content_list[0] if content_list else ""
        if first_line and not any(key in first_line for key in ["ë©´ì ", "ê²½ì‚¬", "IC", "ì œì•½", "ì´ì "]):
            location_name = first_line
        
        display_name = f"í›„ë³´ì§€ {candidate_id}"
        if location_name:
            display_name = f"{candidate_id} - {location_name}"
        
        candidate = {
            "name": display_name,
            "title": header,
            "area_m2": area_m2,
            "slope_percent": slope_percent,
            "road_distance_m": road_distance_m,
            "facility_distance_m": facility_distance_m,
            "existing_facilities": None,
            "expansion_potential": "ë³´í†µ",
            "land_use": land_use,
            "notes": "\n".join(filter(None, notes)),
            "score": score_value,
            "confidence": data_confidence,
            "summary": summary_text,
            "raw_block": content_text
        }
        parsed_candidates.append(candidate)

    return parsed_candidates

def ensure_pandas_available(feature_name: str) -> bool:
    """
    pandas ì˜ì¡´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸.
    ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ê³  False ë°˜í™˜.
    """
    if pd is not None:
        return True
    
    session_flag = "_pandas_warning_shown"
    if not st.session_state.get(session_flag):
        st.error(
            f"`{feature_name}` ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
            "ëª…ë ¹ì–´ `pip install pandas` ë˜ëŠ” requirements ì„¤ì¹˜ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”."
        )
        st.session_state[session_flag] = True
    return False

# ë¸”ë¡ë“¤ì„ JSON íŒŒì¼ì—ì„œ ë¡œë“œ
def get_example_blocks():
    """blocks.jsonì—ì„œ ì˜ˆì‹œ ë¸”ë¡ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    return load_blocks()

BLOCK_CATEGORY_MAP: Dict[str, str] = {
    "basic_info": "ê¸°ë³¸ ì •ë³´ & ìš”êµ¬ì‚¬í•­",
    "requirements": "ê¸°ë³¸ ì •ë³´ & ìš”êµ¬ì‚¬í•­",
    "project_requirements_parsing": "ê¸°ë³¸ ì •ë³´ & ìš”êµ¬ì‚¬í•­",
    "design_suggestions": "í˜„í™© ë¶„ì„ & ê²€ì¦",
    "accessibility_analysis": "í˜„í™© ë¶„ì„ & ê²€ì¦",
    "zoning_verification": "í˜„í™© ë¶„ì„ & ê²€ì¦",
    "capacity_estimation": "í˜„í™© ë¶„ì„ & ê²€ì¦",
    "feasibility_analysis": "ì‚¬ì—…ì„± & ìš´ì˜ ì „ëµ",
    "business_model_development": "ì‚¬ì—…ì„± & ìš´ì˜ ì „ëµ",
    "market_research_analysis": "ì‚¬ì—…ì„± & ìš´ì˜ ì „ëµ",
    "revenue_model_design": "ì‚¬ì—…ì„± & ìš´ì˜ ì „ëµ",
    "operational_efficiency_strategy": "ì‚¬ì—…ì„± & ìš´ì˜ ì „ëµ",
    "persona_scenario_analysis": "ì‚¬ìš©ì ê²½í—˜ & ìŠ¤í† ë¦¬í…”ë§",
    "storyboard_generation": "ì‚¬ìš©ì ê²½í—˜ & ìŠ¤í† ë¦¬í…”ë§",
    "customer_journey_mapping": "ì‚¬ìš©ì ê²½í—˜ & ìŠ¤í† ë¦¬í…”ë§",
}

CATEGORY_DISPLAY_ORDER: List[str] = [
    "ê¸°ë³¸ ì •ë³´ & ìš”êµ¬ì‚¬í•­",
    "í˜„í™© ë¶„ì„ & ê²€ì¦",
    "ì‚¬ì—…ì„± & ìš´ì˜ ì „ëµ",
    "ì‚¬ìš©ì ê²½í—˜ & ìŠ¤í† ë¦¬í…”ë§",
    "ê¸°íƒ€",
]

def resolve_block_category(block: Dict[str, Any]) -> str:
    if not isinstance(block, dict):
        return "ê¸°íƒ€"
    category = block.get("category")
    if category:
        return category
    block_id = block.get("id")
    return BLOCK_CATEGORY_MAP.get(block_id, "ê¸°íƒ€")

def group_blocks_by_category(blocks: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    grouped: Dict[str, List[Dict[str, Any]]] = {}
    for block in blocks:
        category = resolve_block_category(block)
        grouped.setdefault(category, []).append(block)
    return grouped

def iter_categories_in_order(grouped_blocks: Dict[str, List[Dict[str, Any]]]) -> List[str]:
    def _sort_key(category: str):
        if category in CATEGORY_DISPLAY_ORDER:
            return (CATEGORY_DISPLAY_ORDER.index(category), category)
        return (len(CATEGORY_DISPLAY_ORDER), category)
    return sorted(grouped_blocks.keys(), key=_sort_key)

def create_word_document(project_name, analysis_results):
    """ë¶„ì„ ê²°ê³¼ë¥¼ Word ë¬¸ì„œë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
    doc = Document()
    
    # ì œëª©
    doc.add_heading(f'ê±´ì¶• í”„ë¡œì íŠ¸ ë¶„ì„ ë³´ê³ ì„œ: {project_name}', 0)
    
    # ê° ë¶„ì„ ê²°ê³¼ ì¶”ê°€
    for block_id, result in analysis_results.items():
        # ë¸”ë¡ ì´ë¦„ ì°¾ê¸°
        block_name = "ì‚¬ìš©ì ì •ì˜ ë¸”ë¡"
        if block_id.startswith('custom_'):
            custom_blocks = load_custom_blocks()
            for block in custom_blocks:
                if block['id'] == block_id:
                    block_name = block['name']
                    break
        else:
            example_blocks = get_example_blocks()
            for block in example_blocks:
                if block['id'] == block_id:
                    block_name = block['name']
                    break
        
        # ì„¹ì…˜ ì œëª©
        doc.add_heading(block_name, level=1)
        
        # Word í‘œ í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬
        add_content_with_tables(doc, result)
        doc.add_paragraph()  # ë¹ˆ ì¤„
    
    return doc

def add_content_with_tables(doc, text):
    """í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í‘œëŠ” Word í‘œë¡œ, ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” ë¬¸ë‹¨ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤."""
    import re
    
    lines = text.split('\n')
    i = 0
    
    while i < len(lines):
        line = lines[i].strip()
        
        # í‘œ ì‹œì‘ íŒ¨í„´ í™•ì¸ (ê°œì„ ëœ ë°©ì‹)
        if is_table_line(line):
            # í‘œ ë°ì´í„° ìˆ˜ì§‘
            table_lines = [line]
            i += 1
            
            # ì—°ì†ëœ í‘œ ì¤„ë“¤ ìˆ˜ì§‘ (ê°œì„ ëœ ë°©ì‹)
            while i < len(lines) and is_table_line(lines[i].strip()):
                table_lines.append(lines[i].strip())
                i += 1
            
            # Word í‘œ ìƒì„±
            create_word_table(doc, table_lines)
            continue
        
        # ì¼ë°˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        if line:
            # Markdown í—¤ë” ì²˜ë¦¬
            if line.startswith('#'):
                level = len(line) - len(line.lstrip('#'))
                header_text = line.lstrip('#').strip()
                doc.add_heading(header_text, level=min(level, 6))
            else:
                # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
                if line.startswith('- '):
                    line = 'â€¢ ' + line[2:]
                elif line.startswith('* '):
                    line = 'â€¢ ' + line[2:]
                
                # ë³¼ë“œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ (**text**)
                line = re.sub(r'\*\*(.*?)\*\*', r'\1', line)
                
                doc.add_paragraph(line)
        
        i += 1

def create_word_table(doc, table_lines):
    """Markdown í‘œ ì¤„ë“¤ì„ Word í‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not table_lines:
        return
    
    # í‘œ ë°ì´í„° íŒŒì‹±
    table_data = []
    for line in table_lines:
        # |ë¡œ êµ¬ë¶„ëœ ì…€ë“¤ ì¶”ì¶œ
        cells = [cell.strip() for cell in line.split('|')[1:-1]]  # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ë¹ˆ ìš”ì†Œ ì œê±°
        if cells:
            table_data.append(cells)
    
    if not table_data:
        return
    
    # ì²« ë²ˆì§¸ í–‰ì´ í—¤ë” êµ¬ë¶„ì„ ì¸ì§€ í™•ì¸ (--- í˜•íƒœ)
    if len(table_data) > 1 and all(cell == '---' or cell == '------' or cell == '' for cell in table_data[1]):
        headers = table_data[0]
        data_rows = table_data[2:]
    else:
        headers = None
        data_rows = table_data
    
    # ì—´ ìˆ˜ ê²°ì •
    max_cols = max(len(row) for row in table_data) if table_data else 2
    
    # Word í‘œ ìƒì„± - ê°œì„ ëœ ë°©ì‹
    try:
        table = doc.add_table(rows=len(data_rows) + (1 if headers else 0), cols=max_cols)
        table.style = 'Table Grid'
        
        # í‘œ ìë™ í¬ê¸° ì¡°ì ˆ í™œì„±í™”
        table.allow_autofit = True
        table.autofit = True
        
        # í—¤ë” ì¶”ê°€
        if headers:
            header_row = table.rows[0]
            for i, header in enumerate(headers):
                if i < len(header_row.cells):
                    cell = header_row.cells[i]
                    cell.text = clean_text_for_pdf(header)
                    
                    # í—¤ë” ìŠ¤íƒ€ì¼ë§ ê°•í™”
                    for paragraph in cell.paragraphs:
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                        for run in paragraph.runs:
                            run.bold = True
                            run.font.size = Pt(10)
                        # ì…€ íŒ¨ë”© ì¡°ì •
                        paragraph.paragraph_format.space_before = Pt(2)
                        paragraph.paragraph_format.space_after = Pt(2)
        
        # ë°ì´í„° í–‰ ì¶”ê°€
        start_row = 1 if headers else 0
        for i, row_data in enumerate(data_rows):
            if start_row + i < len(table.rows):
                table_row = table.rows[start_row + i]
                for j, cell_data in enumerate(row_data):
                    if j < len(table_row.cells):
                        cell = table_row.cells[j]
                        cell.text = clean_text_for_pdf(cell_data)
                        
                        # ì…€ ìŠ¤íƒ€ì¼ë§
                        for paragraph in cell.paragraphs:
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                            for run in paragraph.runs:
                                run.font.size = Pt(9)
                            # ì…€ íŒ¨ë”© ì¡°ì •
                            paragraph.paragraph_format.space_before = Pt(1)
                            paragraph.paragraph_format.space_after = Pt(1)
        
        # í‘œ í›„ ë¹ˆ ì¤„ ì¶”ê°€
        doc.add_paragraph()
        
    except Exception as e:
        print(f"Word í‘œ ìƒì„± ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´
        doc.add_paragraph("[í‘œ ìƒì„± ì‹¤íŒ¨ - ì›ë³¸ ë°ì´í„°]")
        for row in table_data:
            doc.add_paragraph(" | ".join(row))
        doc.add_paragraph()

def is_table_line(line):
    """í•œ ì¤„ì´ í‘œ í–‰ì¸ì§€ í™•ì¸"""
    if not line:
        return False

    # | êµ¬ë¶„ìê°€ ìˆëŠ” ê²½ìš° (ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹)
    if '|' in line and line.count('|') >= 2:
        return True

    # íƒ­ìœ¼ë¡œ êµ¬ë¶„ëœ ê²½ìš°
    if '\t' in line:
        return True

    # 2ê°œ ì´ìƒì˜ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ê²½ìš° (ì •ë ¬ëœ í…ìŠ¤íŠ¸)
    if re.search(r'\s{2,}', line):
        return True

    return False

def render_structured_response(response: dict):
    """JSON êµ¬ì¡°í™”ëœ ì‘ë‹µì„ Streamlitìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤.

    Args:
        response: AnalysisResponse ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ëŠ” ë”•ì…”ë„ˆë¦¬
            - summary: ìš”ì•½ í…ìŠ¤íŠ¸
            - sections: ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
            - conclusion: ê²°ë¡  (ì„ íƒ)
    """
    if not response or not isinstance(response, dict):
        st.warning("ì‘ë‹µ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # ìš”ì•½ ë Œë”ë§
    summary = response.get('summary', '')
    if summary:
        st.markdown("### ğŸ“‹ ë¶„ì„ ìš”ì•½")
        st.markdown(summary)
        st.markdown("---")

    # ì„¹ì…˜ë³„ ë Œë”ë§
    sections = response.get('sections', [])
    for idx, section in enumerate(sections):
        if not isinstance(section, dict):
            continue

        title = section.get('title', f'ì„¹ì…˜ {idx + 1}')
        content = section.get('content', '')
        table_data = section.get('table')
        table_explanation = section.get('table_explanation', '')

        # ì„¹ì…˜ ì œëª©
        st.markdown(f"### {title}")

        # ì„¹ì…˜ ë³¸ë¬¸
        if content:
            st.markdown(content)

        # í‘œ ë Œë”ë§
        if table_data and isinstance(table_data, dict):
            headers = table_data.get('headers', [])
            rows = table_data.get('rows', [])
            caption = table_data.get('caption', '')

            if headers and rows:
                try:
                    # í–‰ì˜ ì—´ ê°œìˆ˜ë¥¼ í—¤ë”ì— ë§ì¶¤
                    max_cols = len(headers)
                    normalized_rows = []
                    for row in rows:
                        if len(row) < max_cols:
                            row = list(row) + [''] * (max_cols - len(row))
                        elif len(row) > max_cols:
                            row = row[:max_cols]
                        normalized_rows.append(row)

                    df = pd.DataFrame(normalized_rows, columns=headers)

                    if caption:
                        st.caption(caption)

                    st.dataframe(df, use_container_width=True, hide_index=True)
                except Exception as e:
                    st.error(f"í‘œ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                    # í´ë°±: ì›ë³¸ ë°ì´í„° í‘œì‹œ
                    st.json(table_data)

        # í‘œ í•´ì„¤
        if table_explanation:
            st.markdown(f"**[í‘œ í•´ì„¤]** {table_explanation}")

        st.markdown("")  # ì„¹ì…˜ ê°„ ì—¬ë°±

    # ê²°ë¡  ë Œë”ë§
    conclusion = response.get('conclusion', '')
    if conclusion:
        st.markdown("---")
        st.markdown("### ğŸ¯ ê²°ë¡ ")
        st.markdown(conclusion)


def render_analysis_result(result):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤.

    - dictì´ê³  'sections' í‚¤ê°€ ìˆìœ¼ë©´: render_structured_response ì‚¬ìš©
    - ê·¸ ì™¸: render_markdown_with_tables ì‚¬ìš©
    """
    if isinstance(result, dict) and 'sections' in result:
        render_structured_response(result)
    elif isinstance(result, str):
        render_markdown_with_tables(result)
    elif isinstance(result, dict) and 'analysis' in result:
        # ë¶„ì„ ê²°ê³¼ê°€ ë˜í•‘ëœ ê²½ìš°
        analysis = result.get('analysis')
        if isinstance(analysis, dict) and 'sections' in analysis:
            render_structured_response(analysis)
        else:
            render_markdown_with_tables(str(analysis) if analysis else "")
    else:
        st.warning("ì•Œ ìˆ˜ ì—†ëŠ” ê²°ê³¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        st.json(result) if isinstance(result, dict) else st.text(str(result))


def render_markdown_with_tables(text):
    """ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ ë Œë”ë§í•˜ë©´ì„œ í…Œì´ë¸”ì€ st.dataframe()ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not text or not isinstance(text, str):
        return

    lines = text.split('\n')
    i = 0
    buffer = []  # ì¼ë°˜ í…ìŠ¤íŠ¸ ë²„í¼

    while i < len(lines):
        line = lines[i]
        stripped = line.strip()

        # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ì‹œì‘ ê°ì§€ (| êµ¬ë¶„ì ê¸°ì¤€)
        if '|' in stripped and stripped.count('|') >= 2:
            # ë²„í¼ì— ìˆëŠ” í…ìŠ¤íŠ¸ ë¨¼ì € ì¶œë ¥
            if buffer:
                st.markdown('\n'.join(buffer))
                buffer = []

            # í…Œì´ë¸” ë¼ì¸ ìˆ˜ì§‘
            table_lines = [stripped]
            i += 1
            while i < len(lines):
                next_line = lines[i].strip()
                if '|' in next_line and next_line.count('|') >= 2:
                    table_lines.append(next_line)
                    i += 1
                else:
                    break

            # í…Œì´ë¸”ì„ DataFrameìœ¼ë¡œ ë³€í™˜
            if len(table_lines) >= 2 and pd is not None:
                try:
                    # íŒŒì‹± - êµ¬ë¶„ì„ (--- íŒ¨í„´) í–‰ì€ ì œì™¸
                    parsed_rows = []
                    for tl in table_lines:
                        parts = tl.split('|')
                        # ì‹œì‘ê³¼ ëì˜ ë¹ˆ ë¬¸ìì—´ ì œê±° (| ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ëë‚˜ëŠ” ê²½ìš°)
                        if parts and parts[0].strip() == '':
                            parts = parts[1:]
                        if parts and parts[-1].strip() == '':
                            parts = parts[:-1]
                        cells = [c.strip() for c in parts]

                        # êµ¬ë¶„ì„  í–‰ì¸ì§€ í™•ì¸ (ëª¨ë“  ì…€ì´ ---, :---, ---:, :---: íŒ¨í„´ì´ê±°ë‚˜ ë¹ˆ ê²½ìš°)
                        if cells:
                            is_separator_row = all(
                                re.match(r'^[-:]+$', c) or c == ''
                                for c in cells
                            )
                            # êµ¬ë¶„ì„  í–‰ì€ ê±´ë„ˆë›°ê¸°
                            if not is_separator_row:
                                parsed_rows.append(cells)

                    if len(parsed_rows) >= 1:
                        # ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ, ë‚˜ë¨¸ì§€ë¥¼ ë°ì´í„°ë¡œ ì‚¬ìš©
                        headers = parsed_rows[0]
                        data = parsed_rows[1:] if len(parsed_rows) > 1 else []

                        # DataFrame ìƒì„±
                        if data:
                            max_cols = len(headers)
                            normalized_data = []
                            for row in data:
                                if len(row) < max_cols:
                                    row = row + [''] * (max_cols - len(row))
                                elif len(row) > max_cols:
                                    row = row[:max_cols]
                                normalized_data.append(row)

                            df = pd.DataFrame(normalized_data, columns=headers)
                            st.dataframe(df, use_container_width=True, hide_index=True)
                            continue
                        elif headers:
                            # ë°ì´í„°ê°€ ì—†ê³  í—¤ë”ë§Œ ìˆëŠ” ê²½ìš°
                            df = pd.DataFrame(columns=headers)
                            st.dataframe(df, use_container_width=True, hide_index=True)
                            continue
                except Exception as e:
                    pass

            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì¶œë ¥
            st.code('\n'.join(table_lines), language=None)
            continue

        # ì¼ë°˜ ë¼ì¸ì€ ë²„í¼ì— ì¶”ê°€
        buffer.append(line)
        i += 1

    # ë‚¨ì€ ë²„í¼ ì¶œë ¥
    if buffer:
        st.markdown('\n'.join(buffer))

def is_table_format(text):
    """í…ìŠ¤íŠ¸ê°€ í‘œ í˜•ì‹ì¸ì§€ í™•ì¸"""
    try:
        if not text or not isinstance(text, str):
            return False
            
        lines = text.strip().split('\n')
        if len(lines) < 2:
            return False
        
        # 1. ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ í™•ì¸ (| êµ¬ë¶„ì)
        pipe_count = text.count('|')
        if pipe_count >= 3:  # ìµœì†Œ 1x2 í‘œë¥¼ ìœ„í•´ì„œëŠ” 3ê°œì˜ | í•„ìš”
            # êµ¬ë¶„ì„ ì´ ìˆëŠ”ì§€ í™•ì¸ (í‘œì˜ íŠ¹ì§•)
            for line in lines:
                line = line.strip()
                if re.match(r'^[\s\-=_:|]+\s*$', line):
                    return True
            # êµ¬ë¶„ì„ ì´ ì—†ì–´ë„ |ê°€ ë§ì´ ìˆìœ¼ë©´ í‘œë¡œ ê°„ì£¼
            if pipe_count >= 6:
                return True
        
        # 2. êµ¬ë¶„ì„  í™•ì¸ (ë§ˆí¬ë‹¤ìš´ í‘œ êµ¬ë¶„ì„ )
        for line in lines:
            line = line.strip()
            if re.match(r'^[\s\-=_:|]+\s*$', line):
                return True
        
        # 3. íƒ­ êµ¬ë¶„ì í™•ì¸
        tab_count = sum(1 for line in lines if '\t' in line)
        if tab_count >= 2:
            return True
        
        return False
        
    except Exception as e:
        print(f"í‘œ í˜•ì‹ í™•ì¸ ì˜¤ë¥˜: {e}")
        return False

def clean_text_for_pdf(text):
    """PDF/Wordìš© í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text:
        return ""
    
    import re
    
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', '', text)
    
    # Markdown ë³¼ë“œ ì œê±° (**text** -> text)
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
    
    # Markdown ì´íƒ¤ë¦­ ì œê±° (*text* -> text)
    text = re.sub(r'\*(.*?)\*', r'\1', text)
    
    # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
    text = text.replace('&nbsp;', ' ')
    text = text.replace('&amp;', '&')
    text = text.replace('&lt;', '<')
    text = text.replace('&gt;', '>')
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()

def _extract_first_number(text, pattern, default=None, transform=None):
    if not text:
        return default
    match = re.search(pattern, text, re.IGNORECASE)
    if not match:
        return default
    value_text = match.group(1)
    try:
        value = float(value_text.replace(',', '').replace(' ', ''))
    except ValueError:
        return default
    return transform(value) if transform else value

def _parse_area_requirement(structured_text):
    default_area = 330000
    if not structured_text:
        return default_area
    # ã¡ ë‹¨ìœ„ ìš°ì„  íƒìƒ‰
    area = _extract_first_number(structured_text, r'([\d,]+)\s*ã¡', default=None)
    if area:
        return int(area)
    # "ë§Œ í‰" í˜•íƒœ íƒìƒ‰
    match = re.search(r'(\d+)\s*ë§Œ\s*í‰', structured_text)
    if match:
        area_pyong = int(match.group(1)) * 10000
        return int(area_pyong * 3.3058)
    # ì¼ë°˜ "í‰" í˜•íƒœ íƒìƒ‰
    match = re.search(r'([\d,]+)\s*í‰', structured_text)
    if match:
        area_pyong = float(match.group(1).replace(',', ''))
        return int(area_pyong * 3.3058)
    return default_area

def _parse_slope_requirement(structured_text):
    return _extract_first_number(structured_text, r'ê²½ì‚¬ë„[^0-9]*([\d.]+)\s*%', default=5.0)

def _parse_road_requirement(structured_text):
    return _extract_first_number(structured_text, r'ë„ë¡œ[^0-9]*([\d,]+)\s*km', default=None, transform=lambda v: int(v * 1000))

def _parse_priority_weights(structured_text):
    default_weights = {
        "ì ‘ê·¼ì„±": 30,
        "ì—°ê³„ì„±": 25,
        "í™•ì¥ì„±": 20,
        "ê²½ì œì„±": 15,
        "ê³µê³µì„±": 10
    }
    if not structured_text:
        return default_weights
    pattern = r'([ê°€-í£A-Za-z]+)\s*\((\d+)%\)'
    matches = re.findall(pattern, structured_text)
    found = {}
    for name, perc in matches:
        try:
            value = int(perc)
        except ValueError:
            continue
        for key in default_weights.keys():
            if key in name:
                found[key] = value
                break
    return {**default_weights, **found}

def derive_phase1_defaults():
    structured_text = st.session_state.get('phase1_requirements_structured', '')
    defaults = {
        "min_area": _parse_area_requirement(structured_text),
        "max_slope": _parse_slope_requirement(structured_text),
        "max_road_distance": _parse_road_requirement(structured_text) or 1000,
        "weights": _parse_priority_weights(structured_text)
    }
    return defaults

def filter_candidate_sites(min_area, max_slope, max_road_distance, include_expansion, sites=None):
    if sites is None:
        sites = get_phase1_candidate_sites()
    if not sites:
        return []
    filtered = []
    for site in sites:
        area_m2 = site.get("area_m2")
        slope_percent = site.get("slope_percent")
        road_distance = site.get("road_distance_m")
        if area_m2 is None or area_m2 < min_area:
            continue
        if slope_percent is None or slope_percent > max_slope:
            continue
        if road_distance is None or road_distance > max_road_distance:
            continue
        if include_expansion and site.get("expansion_potential") not in ["ìš°ìˆ˜", "ë³´í†µ", "ë†’ìŒ", "ì¤‘ê°„"]:
            continue
        filtered.append(site)
    return filtered

# Phase 1.3ì—ì„œ AIê°€ ìƒì„±í•œ ì‹œì„¤ ëª©ë¡ì„ ì‚¬ìš©í•˜ë¯€ë¡œ í•˜ë“œì½”ë”©ëœ FACILITY_LIBRARYëŠ” ì œê±°ë¨

def render_phase1_1(project_name, location, project_goals, additional_info):
    st.markdown("### Mission 1 Â· Phase 1.1 â€” ìš”êµ¬ì‚¬í•­ ì •ë¦¬")
    st.caption("ğŸŸ¨ í•™ìƒ ì…ë ¥ â†’ ğŸŸ¦ ìì²´ í”„ë¡œê·¸ë¨\n\n1) ê³ ì • í”„ë¡œê·¸ë¨ ì‚¬ì–‘ í™•ì¸\n2) í•™ìƒì´ ì›Œí¬ì‹œíŠ¸ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ê³ \n3) í”„ë¡œê·¸ë¨ì´ êµ¬ì¡°í™”ëœ ìš”êµ¬ì‚¬í•­ ìš”ì•½(ë¸”ë¡ 1)ê³¼ ë°ì´í„° ì²´í¬ë¦¬ìŠ¤íŠ¸(ë¸”ë¡ 2)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    with st.expander("ê³ ì • í”„ë¡œê·¸ë¨ ì‚¬ì–‘ (ì‚¼ì²™ ìŠ¤í¬ì¸ ì•„ì¹´ë°ë¯¸)", expanded=False):
        st.write("ì•„ë˜ í•­ëª©ì€ í•™ìƒì´ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìœ¼ë©°, ë¸”ë¡ 1ê³¼ ë¸”ë¡ 2 ì‹¤í–‰ ì‹œ í•¨ê»˜ ì „ë‹¬ë©ë‹ˆë‹¤.")
        st.text_area(
            "ë„ì… ì„¤ëª…",
            key="phase1_program_intro",
            height=80,
            placeholder="ì˜ˆ: ì‚¼ì²™ ìŠ¤í¬ì¸ ì•„ì¹´ë°ë¯¸ì˜ í•µì‹¬ ë°©í–¥ì„±ê³¼ ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ì„ ê°„ë‹¨íˆ ì…ë ¥í•˜ì„¸ìš”.",
            help="í”„ë¡œê·¸ë¨ ì „ë°˜ì— ëŒ€í•œ ì†Œê°œë‚˜ ì£¼ì˜ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”."
        )
        st.markdown("#### êµìœ¡ ì‹œì„¤")
        st.text_area(
            "êµìœ¡ ì‹œì„¤ í•­ëª©",
            key="phase1_program_education",
            height=120,
            placeholder="- í•™êµ: êµ­ì œí•™êµ(ì¤‘/ê³ )ì™€ êµ­ë‚´ ê³ ë“±í•™êµ (í•™ë…„ ë‹¹ ì•½ 100ëª… ì •ì›)\n- ë¶€ëŒ€ì‹œì„¤: ì‹ë‹¹, ìƒí™œê´€, ê°•ë‹¹ ë“±\n- ì°¸ê³  ì‚¬ë¡€: ì œì£¼ êµ­ì œí•™êµ ë° ì„œìš¸ì²´ìœ¡ê³ ë“±í•™êµ",
            help="êµìœ¡ ì‹œì„¤ ê´€ë ¨ ìš”êµ¬ì‚¬í•­ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”."
        )
        st.markdown("#### ìŠ¤í¬ì¸  ì§€ì›ì‹œì„¤")
        st.text_area(
            "ìŠ¤í¬ì¸  ì§€ì›ì‹œì„¤ í•­ëª©",
            key="phase1_program_sports",
            height=140,
            placeholder="- í•µì‹¬ì¢…ëª©: í…Œë‹ˆìŠ¤, ì–‘ê¶, ë°°ë“œë¯¼í„´, íœì‹±\n- ì¶”ê°€ì¢…ëª©: ì•„ì´ìŠ¤í•˜í‚¤, ì»¬ë§ ë“±\n- í™•ì¥ì¢…ëª©: ëŸ¬ë‹ë§ˆë¼í†¤, ì•¼êµ¬, ì¶•êµ¬ ë“±\n- í™•ì¥ ì „ëµ: ë‹¨ê³„ì  í™•ëŒ€ ê³„íš",
            help="í•µì‹¬/ì¶”ê°€/í™•ì¥ ì¢…ëª© ë“±ì„ ì…ë ¥í•˜ì„¸ìš”."
        )
        st.markdown("#### ì»¨ë²¤ì…˜ ì‹œì„¤")
        st.text_area(
            "ì»¨ë²¤ì…˜ ì‹œì„¤ í•­ëª©",
            key="phase1_program_convention",
            height=100,
            placeholder="- 200ì‹¤ ê·œëª¨ í˜¸í…”\n- êµ­ì œ ì»¨ë²¤ì…˜ í™€\n- ì„ ìˆ˜/ë°©ë¬¸ê° í¸ì˜ ë¦¬í…Œì¼ ì‹œì„¤",
            help="í˜¸í…”, ì»¨ë²¤ì…˜, ë¦¬í…Œì¼ ë“± ë°©ë¬¸ê° ê´€ë ¨ ì‹œì„¤ì„ ì…ë ¥í•˜ì„¸ìš”."
        )
        st.markdown("#### ì¬í™œ/ì›°ë‹ˆìŠ¤")
        st.text_area(
            "ì¬í™œ/ì›°ë‹ˆìŠ¤ í•­ëª©",
            key="phase1_program_wellness",
            height=100,
            placeholder="- ìŠ¤í¬ì¸  ì˜í•™Â·ì¬í™œì„¼í„°\n- ì›°ë‹ˆìŠ¤ í”„ë¡œê·¸ë¨ ë° ê¸°ì—… ì…ì£¼ì‹œì„¤",
            help="ì¬í™œì„¼í„°, ì›°ë‹ˆìŠ¤ í”„ë¡œê·¸ë¨ ë“±ì˜ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”."
        )
        st.markdown("#### ê¸°íƒ€ ì‹œì„¤")
        st.text_area(
            "ê¸°íƒ€ ì‹œì„¤ í•­ëª©",
            key="phase1_program_other",
            height=120,
            placeholder="- ì£¼ë¯¼ ê°œë°©ì‹œì„¤\n- êµ­ì œ ìº í”„ì¥, ì¶•ì œ ê´€ë ¨ ì‹œì„¤ ë“±",
            help="ê·¸ ë°–ì— í¬í•¨í•˜ê³  ì‹¶ì€ ê¸°íƒ€ ì‹œì„¤ì„ ì…ë ¥í•˜ì„¸ìš”."
        )

    with st.expander("ë‹¨ê³„ 1-1-1 Â· í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì›Œí¬ì‹œíŠ¸ ì…ë ¥", expanded=not st.session_state.get('phase1_requirements_structured')):
        st.markdown(
            """**ì›Œí¬ì‹œíŠ¸ ì…ë ¥ í…œí”Œë¦¿**

    **1. í”„ë¡œì íŠ¸ ëª©í‘œ (í•„ìˆ˜)**  
    ìš°ë¦¬ê°€ ë§Œë“¤ê³  ì‹¶ì€ ì•„ì¹´ë°ë¯¸ëŠ”? (ìµœì†Œ 1ê°€ì§€ ì´ìƒ ì‘ì„±)  
    â–¡ ì—˜ë¦¬íŠ¸ ì„ ìˆ˜ë¥¼ í‚¤ì›Œì„œ í•´ì™¸ ì§„ì¶œì‹œí‚¤ëŠ” ê³³  
    â–¡ ì§€ì—­ ì£¼ë¯¼ë„ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê°œë°©ëœ ê³µê°„  
    â–¡ ì‚¬ê³„ì ˆ ìš´ì˜ ê°€ëŠ¥í•œ ë³µí•©ì‹œì„¤  
    â–¡ ê¸°íƒ€: _________________________________  
    â–¡ ê¸°íƒ€: _________________________________  
    â†’ ìš°ë¦¬ íŒ€ í•µì‹¬: "_______________________"  

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  

    **2. ê·œëª¨**  
    - í•™ìƒ ìˆ˜: ì•½ _____ëª… (í•„ìˆ˜)  
    TIP: 100-300ëª… ì‚¬ì´ê°€ ì¼ë°˜ì   
    - ë©´ì : ëŒ€ëµ _____ë§Œ í‰ (ì„ íƒ)  
    TIP: ëª¨ë¥´ë©´ ë¹„ì›Œë‘ì„¸ìš”  
    - ì˜ˆì‚°: _____ì–µ (ì„ íƒ)  
    TIP: "ëª¨ë¥´ê² ìŒ" ë˜ëŠ” "ì œì•½ ì—†ìŒ" ì„ íƒ ê°€ëŠ¥  

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  

    **3. ì œì•½ì¡°ê±´ (ì„ íƒ)**  
    ìš°ë¦¬ í”„ë¡œì íŠ¸ì—ì„œ ê¼­ ê³ ë ¤í•´ì•¼ í•  ì œì•½ì€?  
    ì•„ë˜ ì˜ˆì‹œ ì°¸ê³ í•´ì„œ ììœ ë¡­ê²Œ ì‘ì„±:  
    - ì‚¼ì²™ì‹œì˜ ì¸êµ¬ê°€ ì ì–´ì„œ ì§€ì—­ë§Œìœ¼ë¡œëŠ” í•™ìƒ ëª¨ì§‘ì´ ì–´ë ¤ì›€  
    - ê²¨ìš¸ì— ê´€ê´‘ê°ì´ ì ì–´ì„œ ìˆ˜ìµì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ  
    - ì‚°ì§€ê°€ ë§ì•„ì„œ í‰í‰í•œ ë•…ì´ ë¶€ì¡±í•¨  
    ìš°ë¦¬ íŒ€ ì œì•½:  
    â–¡ _________________________________  
    â–¡ _________________________________  
    â–¡ _________________________________  

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  

    **4. ìš°ì„ ìˆœìœ„ (í•„ìˆ˜ - ìµœì†Œ 3ê°œ ì„ íƒ)**  
    ë¬´ì—‡ì´ ê°€ì¥ ì¤‘ìš”í•œê°€? ë²ˆí˜¸ë¥¼ ë§¤ê²¨ë³´ì„¸ìš”.  
    [  ] êµí†µ ì ‘ê·¼ì„± (ê³ ì†ë„ë¡œ, ì—­, ê³µí•­)  
    [  ] ê¸°ì¡´ ì²´ìœ¡ì‹œì„¤ê³¼ì˜ ì—°ê³„  
    [  ] í™•ì¥ ê°€ëŠ¥ì„±  
    [  ] ê²½ì œì„± (ì €ë ´í•œ í† ì§€)  
    [  ] ì£¼ë¯¼ ì ‘ê·¼ì„±  
    [  ] ì¢‹ì€ ê²½ê´€/í™˜ê²½  
    [  ] ê¸°íƒ€: _____________  
    TIP:  
    - 1, 2, 3... ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ ë§¤ê¸°ê¸°  
    - ìµœì†Œ 3ê°œëŠ” ì„ íƒí•´ì£¼ì„¸ìš”  
    - "ì™œ ì´ê²Œ ì¤‘ìš”í•œê°€?" ê°„ë‹¨íˆ ë©”ëª¨í•´ë„ ì¢‹ì•„ìš”  

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  

    **5. í•µì‹¬ ê°€ì¹˜ (í•„ìˆ˜)**  
    ì´ ì•„ì¹´ë°ë¯¸ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•˜ë©´?  
    ì˜ˆì‹œ:  
    - "ì„¸ê³„ ë¬´ëŒ€ë¡œ ê°€ëŠ” ì§€ë¦„ê¸¸"  
    - "ì§€ì—­ê³¼ í•¨ê»˜ ì„±ì¥í•˜ëŠ” ìŠ¤í¬ì¸  í—ˆë¸Œ"  
    - "ë°ì´í„°ë¡œ ë§Œë“œëŠ” ì°¨ì„¸ëŒ€ ìŠ¤í¬ì¸  êµìœ¡"  
    â†’ _________________________________________"""
        )
        st.text_area(
            "ì›Œí¬ì‹œíŠ¸ ì „ì²´ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”",
            key="phase1_requirements_text",
            placeholder="ì˜ˆ) ìˆ˜ìš© ì¸ì›, ëª©í‘œ ë©´ì , ìš´ì˜ ëª©í‘œ, ì œì•½ì¡°ê±´ ë“±ì„ ììœ ë¡­ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.",
            height=220,
            help="í•™ìƒë“¤ì´ ì •ë¦¬í•œ ìš”êµ¬ì‚¬í•­ ì›Œí¬ì‹œíŠ¸ ì „ì²´ ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”."
        )
        col_input_actions = st.columns([1, 1])
        with col_input_actions[1]:
            if st.button("ì…ë ¥ ì´ˆê¸°í™”", key="reset_phase1_requirements"):
                st.session_state['phase1_requirements_text'] = ""
                st.session_state.pop('phase1_requirements_cot_history', None)
                st.rerun()

    # ì œê±°ëœ ë¸”ë¡ë“¤: phase1_requirements_structuring, phase1_data_inventory
    # ê´€ë ¨ ì„¹ì…˜ ì œê±°ë¨

    if False:  # ì œê±°ëœ ë¸”ë¡ ì¡°ê±´
        with st.expander("ğŸ“¤ Felo AI ì „ë‹¬ ë°ì´í„° ì •ë¦¬", expanded=False):
            st.markdown("""
            **ì´ ë°ì´í„°ëŠ” Felo AIë¡œ ì „ë‹¬í•˜ì—¬ í›„ë³´ì§€ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.**
            
            ì•„ë˜ ë‚´ìš©ì„ ë³µì‚¬í•˜ì—¬ Felo AIì— ì „ë‹¬í•˜ì„¸ìš”.
            """)

            fixed_program = "\n".join([
                build_fixed_program_markdown(),
                "",
                "## ì…ì§€ ì„ ì • ëª©í‘œ",
                "ì‚¼ì²™ ìŠ¤í¬ì¸ ì•„ì¹´ë°ë¯¸ì˜ ìµœì  ì…ì§€ì™€ ê·œëª¨ë¥¼ ì„ ì •í•˜ê³ , ê´€ë ¨ í”„ë¡œê·¸ë¨ì„ í™•ì •",
                "",
                "## í™œìš© ë°ì´í„°",
                "- ì…ì§€ íŠ¹ì§•",
                "- GIS ê³µê°„ ë°ì´í„°",
                "- êµìœ¡ë°œì „íŠ¹êµ¬ ë²•ê·œ",
                "- ì ‘ê·¼ì„± ë¶„ì„",
                "- ë„ì‹œì¬ìƒ ì ì¬ë ¥ ë°ì´í„°",
                "",
                "## ìµœì¢… ëª©í‘œ",
                "ì‹œê°í™”ëœ ë°ì´í„° ê¸°ë°˜ì˜ ì…ì§€ ì„ ì • ê·¼ê±° ë§ˆë ¨"
            ])

            block1_result = st.session_state.get('phase1_requirements_structured', '')
            block2_result = st.session_state.get('phase1_data_inventory', '')

            felo_data = f"""{fixed_program}

        ---

        ## ìš”êµ¬ì‚¬í•­ êµ¬ì¡°í™” ê²°ê³¼ (ë¸”ë¡ 1)

        {block1_result}

        ---

        ## Felo AI ë¶„ì„ ìš”ì²­ì‚¬í•­

        ìœ„ ìš”êµ¬ì‚¬í•­ê³¼ ë°ì´í„° ëª©ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¼ì²™ì‹œ ë‚´ ìµœì  í›„ë³´ì§€ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

        ### ë¶„ì„ ì¡°ê±´
        - ì…ì§€ íŠ¹ì§• ë¶„ì„
        - GIS ê³µê°„ ë°ì´í„° í™œìš©
        - êµìœ¡ë°œì „íŠ¹êµ¬ ë²•ê·œ ê²€í† 
        - ì ‘ê·¼ì„± í‰ê°€
        - ë„ì‹œì¬ìƒ ì ì¬ë ¥ í‰ê°€

        ### ì¶œë ¥ í˜•ì‹
        - í›„ë³´ì§€ ëª©ë¡ (ìœ„ì¹˜, ë©´ì , ê²½ì‚¬ë„, ë„ë¡œ ì ‘ê·¼ì„± ë“±)
        - ê° í›„ë³´ì§€ë³„ í‰ê°€ ì ìˆ˜
        - ì‹œê°í™”ëœ ì§€ë„ ë°ì´í„°
        """

            st.session_state['phase1_felo_data'] = felo_data

            st.text_area(
                "Felo AI ì „ë‹¬ ë°ì´í„° (ë³µì‚¬í•˜ì—¬ ì‚¬ìš©)",
                value=felo_data,
                height=400,
                key="felo_data_display",
                help="ì „ì²´ ë‚´ìš©ì„ ë³µì‚¬í•˜ì—¬ Felo AIì— ì „ë‹¬í•˜ì„¸ìš”."
            )

            st.download_button(
                label="Felo AI ì „ë‹¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
                data=felo_data,
                file_name="felo_ai_input_data.txt",
                mime="text/plain",
                key="download_felo_data"
            )

            st.info(" ì´ ë°ì´í„°ë¥¼ Felo AIì— ì „ë‹¬í•˜ë©´ í›„ë³´ì§€ ì¶”ì¶œ ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def render_phase1_2(project_name, location, project_goals, additional_info):
    st.markdown("### Mission 1 Â· Phase 1.2 â€” í›„ë³´ì§€ íƒìƒ‰ & ê²€í† ")

    # 1. í›„ë³´ì§€ ê³µê°„ ë°ì´í„° (Shapefile ì—…ë¡œë“œ)
    with st.expander("í›„ë³´ì§€ ê³µê°„ ë°ì´í„° (Shapefile ì—…ë¡œë“œ)", expanded=False):
        st.caption("Felo ë˜ëŠ” ì™¸ë¶€ ë¶„ì„ì—ì„œ ë°›ì€ í›„ë³´ì§€ Shapefile(ZIP)ì„ ì—…ë¡œë“œí•˜ë©´ ì§€ë„ì—ì„œ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        uploaded_shapefiles = st.file_uploader(
            "Shapefile ZIP ì—…ë¡œë“œ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
            type=["zip"],
            accept_multiple_files=True,
            key="phase1_candidate_shapefiles"
        )

        if uploaded_shapefiles:
            if not GEO_LOADER_AVAILABLE or GeoDataLoader is None:
                st.error("GeoDataLoaderë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. geopandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("""
                **ì„¤ì¹˜ ë°©ë²•:**
                
                1. **conda ì‚¬ìš© (ê¶Œì¥):**
                   ```
                   conda install -c conda-forge geopandas
                   ```
                
                2. **pip ì‚¬ìš©:**
                   ```
                   pip install geopandas shapely pyproj
                   ```
                
                3. **install.bat ì‹¤í–‰:**
                   í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ `install.bat`ì„ ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ ì„¤ì¹˜ë©ë‹ˆë‹¤.
                """)
            else:
                loader = GeoDataLoader()
                loaded = 0
                errors = []
                with st.spinner(f"{len(uploaded_shapefiles)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                    for uploaded in uploaded_shapefiles:
                        layer_name = uploaded.name.replace(".zip", "").replace(".ZIP", "")
                        result = loader.load_shapefile_from_zip(uploaded.getvalue(), encoding="cp949")
                        if result.get("success"):
                            validation = validate_shapefile_data(result["gdf"])
                        if validation.get("valid", False):
                            st.session_state['phase1_candidate_geo_layers'][layer_name] = {
                                "gdf": result["gdf"],
                                "info": result
                            }
                            loaded += 1
                        else:
                            issues = ", ".join(validation.get("issues", []))
                            errors.append(f" {layer_name}: {issues or 'ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨'}")
                    else:
                        errors.append(f"[ì‹¤íŒ¨] {layer_name}: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            if loaded:
                st.success(f" {loaded}ê°œ ë ˆì´ì–´ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            for err in errors:
                st.warning(err)

        if st.session_state.get('phase1_candidate_geo_layers'):
            st.markdown("##### ì—…ë¡œë“œëœ ë ˆì´ì–´")
            for layer_name, layer_data in list(st.session_state['phase1_candidate_geo_layers'].items()):
                with st.expander(f"ğŸ“‚ {layer_name}", expanded=False):
                    info = layer_data.get("info", {})
                    st.write(f"- í”¼ì²˜ ìˆ˜: {info.get('feature_count', 0):,}ê°œ")
                    st.write(f"- ì¢Œí‘œê³„: {info.get('crs', 'Unknown')}")
                    st.write(f"- ì»¬ëŸ¼ ìˆ˜: {len(info.get('columns', []))}ê°œ")
                    if st.button("ë ˆì´ì–´ ì‚­ì œ", key=f"phase1_candidate_layer_delete_{layer_name}"):
                        del st.session_state['phase1_candidate_geo_layers'][layer_name]
                        st.rerun()

            if st.session_state.get('phase1_candidate_geo_layers'):
                if GEO_LOADER_AVAILABLE and GeoDataLoader is not None:
                    loader = GeoDataLoader()
                    st.markdown("##### ì§€ë„ ì‹œê°í™”")
                    geo_layers_dict = {
                        lname: ldata["gdf"]
                        for lname, ldata in st.session_state['phase1_candidate_geo_layers'].items()
                    }
                    folium_map = None
                    if st_folium:
                        try:
                            folium_map = loader.create_folium_map_multilayer(geo_layers_dict)
                        except Exception as map_error:  # pragma: no cover
                            st.warning(f"Folium ì§€ë„ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {map_error}")
                            folium_map = None
                    if folium_map and st_folium:
                        st_folium.st_folium(folium_map, width=1100, height=540)
                    else:
                        if pd is None:
                            st.warning("pandasê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ ê°„ë‹¨ ì§€ë„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            st.info("`pip install pandas`ë¥¼ ì‹¤í–‰í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                        else:
                            fallback_frames = []
                            for gdf in geo_layers_dict.values():
                                df_for_map = loader.gdf_to_dataframe_for_map(gdf)
                                if not df_for_map.empty:
                                    fallback_frames.append(df_for_map.head(500))
                            if fallback_frames:
                                fallback_df = pd.concat(fallback_frames, ignore_index=True)
                                st.map(fallback_df, size=20)
                            else:
                                st.info("í‘œì‹œ ê°€ëŠ¥í•œ ì¢Œí‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. `pip install streamlit-folium folium` ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

    # 2. ğŸ—’ï¸ Felo í›„ë³´ì§€ í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°
    with st.expander("ğŸ—’ï¸ Felo í›„ë³´ì§€ í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°", expanded=False):
        st.caption("Felo AIì—ì„œ ë°›ì€ í›„ë³´ì§€ ìš”ì•½ì„ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ë©´ ìë™ìœ¼ë¡œ í‘œì¤€í™”ë©ë‹ˆë‹¤.")
        st.session_state['phase1_candidate_felo_text'] = st.text_area(
            "Felo í›„ë³´ì§€ í…ìŠ¤íŠ¸",
            value=st.session_state.get('phase1_candidate_felo_text', ''),
            height=260,
            placeholder="ì˜ˆ) ğŸ…°ï¸ í›„ë³´ì§€ A - êµë™Â·ì„±ë‚¨ë™ ì¼ì› ...",
            key="phase1_candidate_felo_text_area"
        )
        col_felo_actions = st.columns([1, 1])
        with col_felo_actions[0]:
            if st.button("í…ìŠ¤íŠ¸ íŒŒì‹±", key="phase1_parse_felo_blocks"):
                felo_text = st.session_state.get('phase1_candidate_felo_text', '')
                parsed = parse_felo_candidate_blocks(felo_text)
                if parsed:
                    st.session_state['phase1_candidate_sites'] = parsed
                    st.session_state['phase1_candidate_filtered'] = None
                    st.session_state['phase1_selected_sites'] = [entry["name"] for entry in parsed]
                    st.session_state['phase1_candidate_felo_sections'] = parsed
                    st.session_state['phase1_parse_result'] = f"{len(parsed)}ê°œ íŒŒì‹± ì™„ë£Œ"
                    st.rerun()
                else:
                    st.warning("ì…ë ¥ëœ í…ìŠ¤íŠ¸ì—ì„œ í›„ë³´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # íŒŒì‹± ê²°ê³¼ í‘œì‹œ (rerun í›„ì—ë„ ë³´ì´ë„ë¡)
        if st.session_state.get('phase1_parse_result'):
            st.success(st.session_state['phase1_parse_result'])
            parsed_sites = st.session_state.get('phase1_candidate_sites', [])
            if parsed_sites:
                st.write("**íŒŒì‹±ëœ í›„ë³´ì§€:**")
                for idx, site in enumerate(parsed_sites, 1):
                    st.write(f"{idx}. {site.get('name', 'N/A')}")
        with col_felo_actions[1]:
            if st.button("ì…ë ¥ ì´ˆê¸°í™”", key="phase1_reset_felo_blocks"):
                st.session_state['phase1_candidate_felo_text'] = ""
                st.session_state['phase1_candidate_felo_sections'] = []
                st.session_state.pop('phase1_candidate_sites', None)
                st.session_state.pop('phase1_candidate_filtered', None)
                st.rerun()

    # 3. ğŸ“ í›„ë³´ì§€ ëª©ë¡
    candidate_sites = st.session_state.get('phase1_candidate_sites', [])
    
    if not candidate_sites:
        st.info("í›„ë³´ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Shapefileì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ Felo í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ë„£ì–´ì£¼ì„¸ìš”.")
        return
    
    st.markdown("#### ğŸ“ í›„ë³´ì§€ ëª©ë¡")
    if pd is not None:
        df_sites = pd.DataFrame(candidate_sites)
        df_display = df_sites.rename(columns={
            "name": "í›„ë³´ì§€",
            "area_m2": "ë©´ì (ã¡)",
            "slope_percent": "ê²½ì‚¬ë„(%)",
            "land_use": "í† ì§€ìš©ë„",
            "road_distance_m": "ë„ë¡œê±°ë¦¬(m)",
            "existing_facilities": "ì£¼ë³€ ì²´ìœ¡ì‹œì„¤(ê°œì†Œ)",
            "expansion_potential": "í™•ì¥ ì ì¬ë ¥",
            "facility_distance_m": "í•µì‹¬ì‹œì„¤ ê±°ë¦¬(m)",
            "score": "ì´ì (ì )",
            "confidence": "ë°ì´í„° ì‹ ë¢°ë„",
            "notes": "ë©”ëª¨"
        })
        st.dataframe(df_display, use_container_width=True)
        
        # ì§€ë„ í‘œì‹œ
        lat_series = df_sites.get("lat")
        lon_series = df_sites.get("lon")
        if lat_series is not None and lon_series is not None:
            if lat_series.notnull().any() and lon_series.notnull().any():
                st.markdown("##### ğŸ—ºï¸ í›„ë³´ì§€ ì§€ë„")
                map_df = df_sites[['lat', 'lon']].copy()
                st.map(map_df, size=40, zoom=11)
    else:
        st.warning("pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í›„ë³´ì§€ ëª©ë¡ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("`pip install pandas`ë¥¼ ì‹¤í–‰í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

def render_phase1_3(project_name, location, project_goals, additional_info):
    st.markdown("### Mission 1 Â· Phase 1.3 â€” í”„ë¡œê·¸ë¨ í™•ì •")
    
    # Step 1: ìš”êµ¬ì‚¬í•­ ë¶ˆëŸ¬ì˜¤ê¸°
    with st.expander("ğŸ“„ 1ë‹¨ê³„ Â· ìš”êµ¬ì‚¬í•­ ë¶ˆëŸ¬ì˜¤ê¸°", expanded=not st.session_state.get('phase1_3_requirements_loaded')):
        st.caption("Phase 1.1ì—ì„œ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ì§ì ‘ ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
        
        col_req_source = st.columns([1, 1])
        with col_req_source[0]:
            if st.session_state.get('phase1_requirements_structured'):
                st.success(" Phase 1.1 ìš”êµ¬ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤.")
                if st.button("Phase 1.1 ìš”êµ¬ì‚¬í•­ ì‚¬ìš©", key="phase1_3_use_phase1_requirements"):
                    st.session_state['phase1_3_requirements_text'] = st.session_state['phase1_requirements_structured']
                    st.session_state['phase1_3_requirements_loaded'] = True
                    st.rerun()
            else:
                st.info("Phase 1.1ì„ ë¨¼ì € ì™„ë£Œí•˜ê±°ë‚˜ ì˜¤ë¥¸ìª½ì—ì„œ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.")
        
        with col_req_source[1]:
            manual_req_text = st.text_area(
                "ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥",
                height=150,
                placeholder="ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...",
                key="phase1_3_manual_requirements_input"
            )
            if st.button("ì…ë ¥í•œ ìš”êµ¬ì‚¬í•­ ì‚¬ìš©", key="phase1_3_use_manual_requirements"):
                if manual_req_text.strip():
                    st.session_state['phase1_3_requirements_text'] = manual_req_text
                    st.session_state['phase1_3_requirements_loaded'] = True
                    st.success("ìš”êµ¬ì‚¬í•­ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                    st.rerun()
                else:
                    st.warning("ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if st.session_state.get('phase1_3_requirements_text'):
            st.markdown("##### ë¶ˆëŸ¬ì˜¨ ìš”êµ¬ì‚¬í•­")
            st.text_area(
                "í˜„ì¬ ìš”êµ¬ì‚¬í•­",
                value=st.session_state['phase1_3_requirements_text'],
                height=200,
                disabled=True,
                key="phase1_3_requirements_display"
            )
    
    if not st.session_state.get('phase1_3_requirements_loaded'):
        st.info("â¬†ï¸ ìš”êµ¬ì‚¬í•­ì„ ë¨¼ì € ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”.")
        return
    
    requirements_text = st.session_state.get('phase1_3_requirements_text', '')
    
    # Step 2: í›„ë³´ì§€ ì„ íƒ
    with st.expander("ğŸ“ 2ë‹¨ê³„ Â· í›„ë³´ì§€ ì„ íƒ", expanded=not st.session_state.get('phase1_3_selected_site')):
        st.caption("Phase 1.2ì—ì„œ ê²€í† í•œ í›„ë³´ì§€ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        
        candidate_sites = st.session_state.get('phase1_candidate_sites', [])
        if not candidate_sites:
            st.warning("Phase 1.2ì—ì„œ í›„ë³´ì§€ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            site_options = [site.get('name', f"í›„ë³´ì§€ {i+1}") for i, site in enumerate(candidate_sites)]
            selected_site_name = st.selectbox(
                "ìµœì¢… ì„ íƒ í›„ë³´ì§€",
                options=site_options,
                key="phase1_3_site_selector"
            )
            
            if st.button("ì„ íƒ í™•ì •", key="phase1_3_confirm_site"):
                selected_idx = site_options.index(selected_site_name)
                st.session_state['phase1_3_selected_site'] = candidate_sites[selected_idx]
                st.session_state['phase1_3_selected_site_name'] = selected_site_name
                st.success(f"'{selected_site_name}'ì„(ë¥¼) ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
                st.rerun()
        
        if st.session_state.get('phase1_3_selected_site'):
            selected = st.session_state['phase1_3_selected_site']
            st.info(f"**ì„ íƒëœ í›„ë³´ì§€**: {st.session_state.get('phase1_3_selected_site_name', 'N/A')}")
            col_site_info = st.columns(3)
            col_site_info[0].metric("ë©´ì ", f"{selected.get('area_m2', 0):,.0f}ã¡")
            col_site_info[1].metric("ê²½ì‚¬ë„", f"{selected.get('slope_percent', 0):.1f}%")
            col_site_info[2].metric("ì´ì ", f"{selected.get('score', 0):.1f}ì ")
    
    if not st.session_state.get('phase1_3_selected_site'):
        st.info("â¬†ï¸ í›„ë³´ì§€ë¥¼ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.")
        return
    
    # Step 3: AI ë¸”ë¡ ì‹¤í–‰ (ë¸”ë¡ 5, 6, 7 ì œê±°ë¨)
    # ì œê±°ëœ ë¸”ë¡ë“¤: phase1_facility_program, phase1_facility_area_reference, phase1_facility_area_calculation
    # ê´€ë ¨ ì„¹ì…˜ ì œê±°ë¨



# ë©”ì¸ ì»¨í…ì¸ 
tab_project = tab_blocks = tab_run = tab_download = None  # type: ignore
tab_project, tab_blocks, tab_run, tab_download = st.tabs(
    ["ê¸°ë³¸ ì •ë³´ & íŒŒì¼ ì—…ë¡œë“œ", "ë¶„ì„ ë¸”ë¡ ì„ íƒ", "ë¶„ì„ ì‹¤í–‰", "ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"]
)

project_name = st.session_state.get("project_name", "")
location = st.session_state.get("location", "")
project_goals = st.session_state.get("project_goals", "")
additional_info = st.session_state.get("additional_info", "")

with tab_project:
    st.header("í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ ì…ë ¥")
    st.caption("í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ëŠ” ì´ íƒ­ì—ì„œ ë³„ë„ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤. ì…ë ¥ê°’ì€ ìë™ ì €ì¥ë©ë‹ˆë‹¤.")

    # ë””ë²„ê·¸ ì •ë³´ (ê°œë°œ ì¤‘ í™•ì¸ìš©) - ìˆ¨ê¹€ ì²˜ë¦¬
    # with st.expander("ğŸ” ì„¸ì…˜ ìƒíƒœ í™•ì¸ (ë””ë²„ê·¸)", expanded=False):
    #     st.caption("í˜„ì¬ ì„¸ì…˜ì— ì €ì¥ëœ í”„ë¡œì íŠ¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    #     debug_info = {
    #         "í”„ë¡œì íŠ¸ëª…": st.session_state.get('project_name', '(ì—†ìŒ)'),
    #         "ìœ„ì¹˜": st.session_state.get('location', '(ì—†ìŒ)'),
    #         "ìœ„ë„": st.session_state.get('latitude', '(ì—†ìŒ)'),
    #         "ê²½ë„": st.session_state.get('longitude', '(ì—†ìŒ)'),
    #         "í”„ë¡œì íŠ¸ ëª©í‘œ": st.session_state.get('project_goals', '(ì—†ìŒ)')[:50] + "..." if len(st.session_state.get('project_goals', '')) > 50 else st.session_state.get('project_goals', '(ì—†ìŒ)'),
    #     }
    #     for key, value in debug_info.items():
    #         st.text(f"{key}: {value}")
    #
    #     # DB ì €ì¥ í™•ì¸
    #     if 'pms_current_user' in st.session_state:
    #         user_id = st.session_state.pms_current_user.get('id')
    #         st.text(f"ì‚¬ìš©ì ID: {user_id}")
    #     else:
    #         st.warning("ë¡œê·¸ì¸ ì •ë³´ ì—†ìŒ")

    st.text_input(
        "í”„ë¡œì íŠ¸ëª…",
        value=st.session_state.get("project_name", ""),
        placeholder="ì˜ˆ: ì‚¼ì²™ ìŠ¤í¬ì¸ ì•„ì¹´ë°ë¯¸",
        key="project_name"
    )
    st.text_input(
        "ìœ„ì¹˜/ì§€ì—­",
        value=st.session_state.get("location", ""),
        placeholder="ì˜ˆ: ê°•ì›ë„ ì‚¼ì²™ì‹œ ë„ê³„ì ì¼ëŒ€",
        key="location"
    )
    
    # ì¢Œí‘œ ì…ë ¥ (Google Mapsìš©, ì„ íƒì‚¬í•­)
    with st.expander("ğŸ—ºï¸ ìœ„ì¹˜ ì¢Œí‘œ ì…ë ¥ (Google Mapsìš©, ì„ íƒì‚¬í•­)", expanded=False):
        st.caption("Google Maps ê¸°ë°˜ ê²€ìƒ‰ì„ ìœ„í•´ ìœ„ë„/ê²½ë„ë¥¼ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ì§€ë¦¬ì  ë°ì´í„°ì—ì„œ ìë™ìœ¼ë¡œ ì¶”ì¶œë©ë‹ˆë‹¤.")
        col1, col2 = st.columns(2)
        with col1:
            st.text_input(
                "ìœ„ë„ (Latitude)",
                value=st.session_state.get("latitude", ""),
                placeholder="ì˜ˆ: 37.5665",
                key="latitude",
                help="ìœ„ë„ ê°’ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 37.5665)"
            )
        with col2:
            st.text_input(
                "ê²½ë„ (Longitude)",
                value=st.session_state.get("longitude", ""),
                placeholder="ì˜ˆ: 126.9780",
                key="longitude",
                help="ê²½ë„ ê°’ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 126.9780)"
            )
        if st.session_state.get('latitude') and st.session_state.get('longitude'):
            try:
                lat = float(st.session_state.latitude)
                lon = float(st.session_state.longitude)
                if -90 <= lat <= 90 and -180 <= lon <= 180:
                    st.success(f" ì¢Œí‘œ í™•ì¸: ({lat}, {lon})")
                else:
                    st.warning(" ì¢Œí‘œ ë²”ìœ„ë¥¼ í™•ì¸í•˜ì„¸ìš”. ìœ„ë„: -90~90, ê²½ë„: -180~180")
            except ValueError:
                st.error("âŒ ì¢Œí‘œëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
    
    st.text_area(
        "í”„ë¡œì íŠ¸ ëª©í‘œ",
        value=st.session_state.get("project_goals", ""),
        placeholder="ì˜ˆ: êµ­ì œ ìŠ¤í¬ì¸  ì•„ì¹´ë°ë¯¸ ì¡°ì„±, ì§€ì—­ ê²½ì œ í™œì„±í™”, êµìœ¡Â·í›ˆë ¨ í†µí•© í”„ë¡œê·¸ë¨ êµ¬ì¶• ë“±",
        height=80,
        key="project_goals"
    )
    st.text_area(
        "ì¶”ê°€ ì •ë³´",
        value=st.session_state.get("additional_info", ""),
        placeholder="íŠ¹ë³„í•œ ì œì•½ì¡°ê±´ì´ë‚˜ ì°¸ê³  ì‚¬í•­ì´ ìˆë‹¤ë©´ ì…ë ¥í•˜ì„¸ìš”.",
        height=80,
        key="additional_info"
    )

    # í”„ë¡œì íŠ¸ ì •ë³´ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼
    col_load, col_save = st.columns(2)

    with col_load:
        if st.button("ğŸ“¥ ì €ì¥ëœ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True, key="load_project_info"):
            # ë¶ˆëŸ¬ì˜¤ê¸° í”Œë˜ê·¸ ì„¤ì •í•˜ê³  ì¦‰ì‹œ rerun (ìœ„ì ¯ì´ ìƒì„±ë˜ê¸° ì „ì—)
            st.session_state['_force_load_session'] = True
            st.rerun()

    with col_save:
        save_button_clicked = st.button("âœ… í”„ë¡œì íŠ¸ ì •ë³´ ì €ì¥", use_container_width=True, type="primary", key="save_project_info")

    if save_button_clicked:
        # ì„¸ì…˜ ì €ì¥
        try:
            from auth.session_init import save_work_session, save_analysis_progress
            from database.db_manager import execute_query
            import json
            from datetime import datetime

            # ë¡œê·¸ì¸ í™•ì¸
            if 'pms_current_user' not in st.session_state:
                st.error("âŒ ë¡œê·¸ì¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.")
                st.stop()

            user_id = st.session_state.pms_current_user.get('id')
            if not user_id:
                st.error("âŒ ì‚¬ìš©ì IDë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

            # í˜„ì¬ ì„¸ì…˜ ìƒíƒœ ì¶œë ¥ (ë””ë²„ê·¸)
            print(f"[ì €ì¥] ì‚¬ìš©ì ID: {user_id}")
            print(f"[ì €ì¥] project_name: '{st.session_state.get('project_name')}'")
            print(f"[ì €ì¥] location: '{st.session_state.get('location')}'")
            print(f"[ì €ì¥] project_goals: '{st.session_state.get('project_goals', '')[:50]}...'")

            # ì €ì¥ ì‹¤í–‰
            save_work_session()
            save_analysis_progress(force=True)

            # ì €ì¥ í™•ì¸ (ë””ë²„ê·¸)
            check_result = execute_query(
                "SELECT session_data FROM analysis_sessions WHERE user_id = ? ORDER BY created_at DESC LIMIT 1",
                (user_id,)
            )
            if check_result:
                saved_data = json.loads(check_result[0]['session_data'])
                print(f"[ì €ì¥ í™•ì¸] DBì— ì €ì¥ëœ project_name: '{saved_data.get('project_name')}'")
                print(f"[ì €ì¥ í™•ì¸] DBì— ì €ì¥ëœ location: '{saved_data.get('location')}'")

                # UIì— ì €ì¥ëœ ë‚´ìš© í‘œì‹œ
                st.success("âœ… í”„ë¡œì íŠ¸ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                with st.expander("ì €ì¥ëœ ë‚´ìš© í™•ì¸", expanded=True):
                    st.write(f"**í”„ë¡œì íŠ¸ëª…**: {saved_data.get('project_name', '(ì—†ìŒ)')}")
                    st.write(f"**ìœ„ì¹˜**: {saved_data.get('location', '(ì—†ìŒ)')}")
                    st.write(f"**ì´ {len(saved_data)}ê°œ í•­ëª© ì €ì¥ë¨**")
            else:
                st.warning("âš ï¸ ì €ì¥ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            print(f"[ì €ì¥ ì˜¤ë¥˜ ì „ì²´ ë‚´ì—­]:\n{error_details}")
            st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            with st.expander("ì˜¤ë¥˜ ìƒì„¸ ì •ë³´"):
                st.code(error_details)

    st.markdown("---")
    st.header("íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_file = st.file_uploader(
        "íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['pdf', 'xlsx', 'xls', 'csv', 'txt', 'json'],
        help="ë„ì‹œ í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF, Excel, CSV, í…ìŠ¤íŠ¸, JSON ì§€ì›)"
    )
    
    if uploaded_file is not None:
        st.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        # íŒŒì¼ í™•ì¥ì í™•ì¸
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        # ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ íŒŒì¼ ë¶„ì„ (ì„ì‹œ íŒŒì¼ ìƒì„± ì—†ìŒ)
        file_analyzer = UniversalFileAnalyzer()
        
        # íŒŒì¼ ë¶„ì„ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        with st.spinner(f"{file_extension.upper()} íŒŒì¼ ë¶„ì„ ì¤‘..."):
            analysis_result = file_analyzer.analyze_file_from_bytes(
                uploaded_file.getvalue(), 
                file_extension, 
                uploaded_file.name
            )
            
        if analysis_result['success']:
            st.success(f"{file_extension.upper()} íŒŒì¼ ë¶„ì„ ì™„ë£Œ!")
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ (íŒŒì¼ í¬ê¸°ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ì§ì ‘ ê³„ì‚°)
            file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
            st.info(f"íŒŒì¼ ì •ë³´: {file_size_mb:.2f}MB, {analysis_result['word_count']}ë‹¨ì–´, {analysis_result['char_count']}ë¬¸ì")
            
            # íŒŒì¼ í˜•ì‹ë³„ íŠ¹ë³„ ì •ë³´ í‘œì‹œ
            if analysis_result['file_type'] == 'excel':
                st.info(f"Excel ì‹œíŠ¸: {', '.join(analysis_result['sheet_names'])} ({analysis_result['sheet_count']}ê°œ ì‹œíŠ¸)")
            elif analysis_result['file_type'] == 'csv':
                st.info(f"CSV ë°ì´í„°: {analysis_result['shape'][0]}í–‰ Ã— {analysis_result['shape'][1]}ì—´")
            
            # ì„¸ì…˜ì— ì €ì¥
            st.session_state['pdf_text'] = analysis_result['text']  # ê¸°ì¡´ ë³€ìˆ˜ëª… ìœ ì§€
            st.session_state['pdf_uploaded'] = True
            st.session_state['file_type'] = analysis_result['file_type']
            st.session_state['file_analysis'] = analysis_result
            st.session_state['uploaded_file'] = uploaded_file  # íŒŒì¼ ê°ì²´ ì €ì¥
            
            # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
            with st.expander(f"{file_extension.upper()} ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
                st.text(analysis_result['preview'])

            # íŒŒì¼ ì—…ë¡œë“œ í™•ì¸ ë²„íŠ¼
            if st.button("âœ… íŒŒì¼ ë¶„ì„ ì™„ë£Œ í™•ì¸", use_container_width=True, type="primary", key="confirm_file_upload"):
                try:
                    from auth.session_init import save_work_session, save_analysis_progress
                    save_work_session()
                    save_analysis_progress(force=True)
                    st.success("íŒŒì¼ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! 'ë¶„ì„ ë¸”ë¡ ì„ íƒ' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
                except Exception as e:
                    st.warning(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                    st.success("íŒŒì¼ ë¶„ì„ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. 'ë¶„ì„ ë¸”ë¡ ì„ íƒ' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
        else:
            st.error(f"{file_extension.upper()} íŒŒì¼ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {analysis_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

    # ì…ë ¥ê°’ ìµœì‹ í™”
    project_name = st.session_state.get("project_name", "")
    location = st.session_state.get("location", "")
    project_goals = st.session_state.get("project_goals", "")
    additional_info = st.session_state.get("additional_info", "")

with tab_blocks:
    st.header("ë¶„ì„ ë¸”ë¡ ì„ íƒ")
    
    # ê¸°ë³¸ ì •ë³´ë‚˜ íŒŒì¼ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì§„í–‰
    has_basic_info = any([project_name, location, project_goals, additional_info])
    has_file = st.session_state.get('pdf_uploaded', False)
    
    if not has_basic_info and not has_file:
        st.warning("í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()


    # get_example_blocks()ëŠ” ì´ë¯¸ ëª¨ë“  ë¸”ë¡(custom í¬í•¨)ì„ ë°˜í™˜í•˜ë¯€ë¡œ ì¤‘ë³µ ë°©ì§€
    all_blocks = get_example_blocks()
    block_lookup = {
        block.get('id'): block
        for block in all_blocks
        if isinstance(block, dict) and block.get('id')
    }

    grouped_blocks = group_blocks_by_category(all_blocks)
    
    if not grouped_blocks:
        st.info("ì‚¬ìš© ê°€ëŠ¥í•œ ë¶„ì„ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.subheader("ë¸”ë¡ ëª©ë¡")
        ordered_categories = iter_categories_in_order(grouped_blocks)
        total_categories = len(ordered_categories)
        
        for idx, category in enumerate(ordered_categories):
            st.markdown(f"#### ğŸ“‚ {category}")
            for block_idx, block in enumerate(grouped_blocks[category]):
                block_id = block.get('id')
                if not block_id:
                    continue
                
                is_custom_block = (
                    block.get('created_by') == 'user' or
                    str(block_id).startswith('custom_')
                )
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    # ê³µê°„ ë°ì´í„° ì—°ë™ ì—¬ë¶€ í™•ì¸
                    block_spatial = st.session_state.get('block_spatial_data', {})
                    is_linked = block_id in block_spatial

                    block_name = block.get('name', 'ì´ë¦„ ì—†ìŒ')

                    # ì‚¬ìš©ì ë¸”ë¡ì— [ê°œì¸]/[íŒ€] íƒœê·¸ ì¶”ê°€
                    if is_custom_block or block.get('_db_id'):
                        visibility = block.get('_visibility', block.get('visibility', ''))
                        if visibility in ['personal', 'PERSONAL']:
                            if not block_name.startswith('[ê°œì¸]'):
                                block_name = f"[ê°œì¸] {block_name}"
                        elif visibility in ['team', 'TEAM']:
                            if not block_name.startswith('[íŒ€]'):
                                block_name = f"[íŒ€] {block_name}"

                    if is_linked:
                        linked_layer = block_spatial[block_id].get('layer_name', '')
                        st.markdown(f"**{block_name}** ğŸ“")
                        st.caption(f"ğŸ”— ì—°ë™: {linked_layer}")
                    else:
                        st.markdown(f"**{block_name}**")

                    description = block.get('description')
                    if description:
                        st.caption(description)
                
                with col2:
                    is_selected = block_id in st.session_state['selected_blocks']
                    # ì¹´í…Œê³ ë¦¬ì™€ ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•˜ì—¬ ê³ ìœ í•œ key ìƒì„±
                    unique_key = f"select_{category}_{block_idx}_{block_id}"
                    checkbox_value = st.checkbox(
                        "ì„ íƒ",
                        key=unique_key,
                        value=is_selected
                    )
                    
                    if checkbox_value and not is_selected:
                        st.session_state['selected_blocks'].append(block_id)
                    elif not checkbox_value and is_selected:
                        # ë¶„ì„ ì„¸ì…˜ ì§„í–‰ ì¤‘ì´ê³  cot_planì— ìˆëŠ” ë¸”ë¡ì€ ì œê±°í•˜ì§€ ì•ŠìŒ
                        if st.session_state.get('cot_session') and block_id in st.session_state.get('cot_plan', []):
                            print(f"[DEBUG ì²´í¬ë°•ìŠ¤] ë¸”ë¡ {block_id} ì œê±° ë°©ì§€ (cot_planì— ìˆìŒ)")
                        else:
                            print(f"[DEBUG ì²´í¬ë°•ìŠ¤] ë¸”ë¡ {block_id} ì œê±°ë¨")
                            st.session_state['selected_blocks'].remove(block_id)
            
            if idx < total_categories - 1:
                st.divider()
    
    # ì„ íƒëœ ë¸”ë¡ë“¤ í‘œì‹œ ë° ìˆœì„œ ì¡°ì •
    selected_blocks = st.session_state['selected_blocks']
    if selected_blocks:
        st.success(f"{len(selected_blocks)}ê°œ ë¸”ë¡ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤:")
        
        # ì„ íƒëœ ë¸”ë¡ë“¤ì˜ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ êµ¬ì„±
        import pandas as pd
        
        block_info_list = []
        for order, block_id in enumerate(selected_blocks, start=1):
            block = block_lookup.get(block_id)
            block_name = block.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ') if block else "ì•Œ ìˆ˜ ì—†ìŒ"

            # ì‚¬ìš©ì ë¸”ë¡ì— [ê°œì¸]/[íŒ€] íƒœê·¸ ì¶”ê°€
            if block:
                is_custom = block.get('created_by') == 'user' or str(block_id).startswith('custom_') or block.get('_db_id')
                if is_custom:
                    visibility = block.get('_visibility', block.get('visibility', ''))
                    if visibility in ['personal', 'PERSONAL'] and not block_name.startswith('[ê°œì¸]'):
                        block_name = f"[ê°œì¸] {block_name}"
                    elif visibility in ['team', 'TEAM'] and not block_name.startswith('[íŒ€]'):
                        block_name = f"[íŒ€] {block_name}"

            block_description = block.get('description', '') if block else ""
            block_category = resolve_block_category(block) if block else "ê¸°íƒ€"
            block_info_list.append({
                'ìˆœì„œ': order,
                'ì¹´í…Œê³ ë¦¬': block_category,
                'ë¸”ë¡ëª…': block_name,
                'ì„¤ëª…': block_description,
                'ë¸”ë¡ID': block_id
            })
        
        # ìˆœì„œ ì¡°ì •ì„ ìœ„í•œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(block_info_list)
        
        st.subheader("ì„ íƒëœ ë¸”ë¡ ëª©ë¡ ë° ìˆœì„œ ì¡°ì •")
        st.caption("ğŸ’¡ ìˆœì„œ ì»¬ëŸ¼ì˜ ìˆ«ìë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ê±°ë‚˜, ì˜¤ë¥¸ìª½ì—ì„œ í–‰ì„ ì„ íƒí•˜ì—¬ í™”ì‚´í‘œ ë²„íŠ¼ìœ¼ë¡œ ìˆœì„œë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # í‘œì™€ ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜
        col_table, col_buttons = st.columns([5, 1])
        
        with col_table:
            # ìˆ˜ì • ê°€ëŠ¥í•œ ë°ì´í„° ì—ë””í„°ë¡œ ìˆœì„œ ì¡°ì •
            edited_df = st.data_editor(
                df[['ìˆœì„œ', 'ì¹´í…Œê³ ë¦¬', 'ë¸”ë¡ëª…', 'ì„¤ëª…']],
                use_container_width=True,
                num_rows="fixed",
                key="block_order_editor",
                column_config={
                    "ìˆœì„œ": st.column_config.NumberColumn(
                        "ìˆœì„œ",
                        help="ë¶„ì„ ì‹¤í–‰ ìˆœì„œ (ìˆ«ìê°€ ì‘ì„ìˆ˜ë¡ ë¨¼ì € ì‹¤í–‰)",
                        min_value=1,
                        max_value=len(block_info_list),
                        step=1
                    ),
                    "ì¹´í…Œê³ ë¦¬": st.column_config.TextColumn(
                        "ì¹´í…Œê³ ë¦¬",
                        disabled=True
                    ),
                    "ë¸”ë¡ëª…": st.column_config.TextColumn(
                        "ë¸”ë¡ëª…",
                        disabled=True
                    ),
                    "ì„¤ëª…": st.column_config.TextColumn(
                        "ì„¤ëª…",
                        disabled=True
                    )
                }
            )

            # ìˆœì„œ ë³€ê²½ì‚¬í•­ ê°ì§€ (ì„¸ì…˜ì— ì €ì¥)
            original_order = df['ìˆœì„œ'].tolist()
            edited_order = edited_df['ìˆœì„œ'].tolist()

            # ë³€ê²½ì‚¬í•­ì´ ìˆëŠ”ì§€ í‘œì‹œ
            order_changed = original_order != edited_order
            if order_changed:
                # ì¤‘ë³µ ê²€ì‚¬
                if len(set(edited_order)) != len(edited_order):
                    st.warning("âš ï¸ ìˆœì„œ ê°’ì´ ì¤‘ë³µë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ìœ í•œ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    st.info("âœï¸ ìˆœì„œê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ 'ìˆœì„œ ì ìš©' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                    # ë³€ê²½ëœ ìˆœì„œë¥¼ ì„ì‹œë¡œ ì €ì¥
                    st.session_state['pending_block_order'] = edited_df

        with col_buttons:
            st.markdown("")  # ìƒë‹¨ ì—¬ë°±
            st.markdown("")  # ìƒë‹¨ ì—¬ë°±
            
            # ì„ íƒëœ í–‰ ì¸ë±ìŠ¤ ì´ˆê¸°í™” ë° ìœ íš¨ì„± ê²€ì‚¬
            if 'selected_block_row_index' not in st.session_state:
                st.session_state.selected_block_row_index = 0
            
            # ì¸ë±ìŠ¤ê°€ ìœ íš¨í•œ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
            max_index = len(block_info_list) - 1
            if st.session_state.selected_block_row_index > max_index:
                st.session_state.selected_block_row_index = max_index
            if st.session_state.selected_block_row_index < 0:
                st.session_state.selected_block_row_index = 0
            
            # í–‰ ì„ íƒì„ ìœ„í•œ selectbox
            block_options = [f"{i+1}. {row['ë¸”ë¡ëª…']}" for i, row in df.iterrows()]
            selected_row_display = st.selectbox(
                "í–‰ ì„ íƒ:",
                options=block_options,
                index=st.session_state.selected_block_row_index,
                key="block_row_selector",
                label_visibility="collapsed"
            )
            
            # ì„ íƒëœ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            selected_row_index = block_options.index(selected_row_display)
            st.session_state.selected_block_row_index = selected_row_index
            
            st.markdown("")  # ì—¬ë°±
            
            # ìœ„/ì•„ë˜ í™”ì‚´í‘œ ë²„íŠ¼
            move_up_disabled = (selected_row_index == 0)
            if st.button("â¬†ï¸", key="move_block_up", disabled=move_up_disabled, use_container_width=True, help="ìœ„ë¡œ ì´ë™"):
                if selected_row_index > 0:
                    current_blocks = st.session_state['selected_blocks'].copy()
                    # ì„ íƒëœ ë¸”ë¡ê³¼ ìœ„ ë¸”ë¡ êµí™˜
                    current_blocks[selected_row_index], current_blocks[selected_row_index - 1] = \
                        current_blocks[selected_row_index - 1], current_blocks[selected_row_index]
                    st.session_state['selected_blocks'] = current_blocks
                    st.session_state.selected_block_row_index = selected_row_index - 1
                    st.success("ë¸”ë¡ì´ ìœ„ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
            
            move_down_disabled = (selected_row_index == len(st.session_state['selected_blocks']) - 1)
            if st.button("â¬‡ï¸", key="move_block_down", disabled=move_down_disabled, use_container_width=True, help="ì•„ë˜ë¡œ ì´ë™"):
                if selected_row_index < len(st.session_state['selected_blocks']) - 1:
                    current_blocks = st.session_state['selected_blocks'].copy()
                    # ì„ íƒëœ ë¸”ë¡ê³¼ ì•„ë˜ ë¸”ë¡ êµí™˜
                    current_blocks[selected_row_index], current_blocks[selected_row_index + 1] = \
                        current_blocks[selected_row_index + 1], current_blocks[selected_row_index]
                    st.session_state['selected_blocks'] = current_blocks
                    st.session_state.selected_block_row_index = selected_row_index + 1
                    st.success("ë¸”ë¡ì´ ì•„ë˜ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()

            # ìˆœì„œ ì§ì ‘ ìˆ˜ì • ì ìš© ë²„íŠ¼
            if 'pending_block_order' in st.session_state:
                st.markdown("")  # ì—¬ë°±
                if st.button("âœ… ìˆœì„œ ì ìš©", key="apply_block_order", type="primary", use_container_width=True, help="í¸ì§‘í•œ ìˆœì„œë¥¼ ì ìš©í•©ë‹ˆë‹¤"):
                    try:
                        pending_df = st.session_state['pending_block_order']
                        edited_order = pending_df['ìˆœì„œ'].tolist()

                        # ì¤‘ë³µ ê²€ì‚¬
                        if len(set(edited_order)) == len(edited_order):
                            sorted_indices = pending_df.sort_values('ìˆœì„œ', kind="stable").index
                            new_blocks = [df.loc[idx, 'ë¸”ë¡ID'] for idx in sorted_indices]
                            st.session_state['selected_blocks'] = new_blocks
                            del st.session_state['pending_block_order']
                            st.success("ë¸”ë¡ ìˆœì„œê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.rerun()
                        else:
                            st.error("ìˆœì„œ ê°’ì´ ì¤‘ë³µë˜ì—ˆìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ìˆœì„œ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")

        # ê³µê°„ ë°ì´í„° ì—°ë™ ì„¹ì…˜
        if st.session_state.get('downloaded_geo_data'):
            st.markdown("---")
            st.subheader("ğŸ”— ê³µê°„ ë°ì´í„° ì—°ë™")
            st.caption("Mappingì—ì„œ ì¡°íšŒí•œ ê³µê°„ ë°ì´í„°ë¥¼ ê° ë¸”ë¡ì˜ ë¶„ì„ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # block_spatial_data ì´ˆê¸°í™”
            if 'block_spatial_data' not in st.session_state:
                st.session_state.block_spatial_data = {}

            # ì‚¬ìš© ê°€ëŠ¥í•œ ë ˆì´ì–´ ëª©ë¡
            available_layers = list(st.session_state.downloaded_geo_data.keys())
            layer_info = {
                layer_name: f"{layer_name} ({data.get('feature_count', 0)}ê°œ)"
                for layer_name, data in st.session_state.downloaded_geo_data.items()
            }

            # ê° ì„ íƒëœ ë¸”ë¡ì— ëŒ€í•´ ë ˆì´ì–´ ì—°ë™ UI
            for block_id in selected_blocks:
                block = block_lookup.get(block_id)
                block_name = block.get('name', block_id) if block else block_id

                # í˜„ì¬ ì—°ë™ëœ ë ˆì´ì–´ ê°€ì ¸ì˜¤ê¸°
                current_linked = []
                if block_id in st.session_state.block_spatial_data:
                    current_linked = st.session_state.block_spatial_data[block_id].get('layers', [])

                col_block, col_layer = st.columns([2, 3])
                with col_block:
                    st.markdown(f"**{block_name}**")
                with col_layer:
                    # multiselectë¡œ ë ˆì´ì–´ ì„ íƒ
                    selected_layers = st.multiselect(
                        "ì—°ë™í•  ë ˆì´ì–´",
                        options=available_layers,
                        default=[l for l in current_linked if l in available_layers],
                        format_func=lambda x: layer_info.get(x, x),
                        key=f"layer_link_{block_id}",
                        label_visibility="collapsed"
                    )

                    # ì„ íƒ ë³€ê²½ ì‹œ block_spatial_data ì—…ë°ì´íŠ¸
                    if selected_layers:
                        combined_features = []
                        total_count = 0
                        for layer_name in selected_layers:
                            if layer_name in st.session_state.downloaded_geo_data:
                                data = st.session_state.downloaded_geo_data[layer_name]
                                geojson = data.get('geojson', {})
                                for feature in geojson.get('features', []):
                                    feature_copy = dict(feature)
                                    if 'properties' not in feature_copy:
                                        feature_copy['properties'] = {}
                                    feature_copy['properties']['_layer'] = layer_name
                                    combined_features.append(feature_copy)
                                total_count += data.get('feature_count', 0)

                        st.session_state.block_spatial_data[block_id] = {
                            'layer_name': ', '.join(selected_layers),
                            'geojson': {'type': 'FeatureCollection', 'features': combined_features},
                            'feature_count': total_count,
                            'layers': selected_layers
                        }
                    elif block_id in st.session_state.block_spatial_data:
                        # ì„ íƒ í•´ì œ ì‹œ ì‚­ì œ
                        del st.session_state.block_spatial_data[block_id]

            # ì—°ë™ í˜„í™© ìš”ì•½
            linked_blocks = [bid for bid in selected_blocks if bid in st.session_state.block_spatial_data]
            if linked_blocks:
                st.success(f"âœ“ {len(linked_blocks)}ê°œ ë¸”ë¡ì— ê³µê°„ ë°ì´í„°ê°€ ì—°ë™ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë¸”ë¡ ì„ íƒ ì™„ë£Œ ë²„íŠ¼
        st.markdown("---")
        if st.button("âœ… ë¸”ë¡ ì„ íƒ ì™„ë£Œ", use_container_width=True, type="primary", key="confirm_block_selection"):
            try:
                from auth.session_init import save_work_session, save_analysis_progress
                save_work_session()
                save_analysis_progress(force=True)
                st.success(f"{len(selected_blocks)}ê°œ ë¸”ë¡ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤! 'ë¶„ì„ ì‹¤í–‰' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
            except Exception as e:
                st.warning(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                st.success(f"{len(selected_blocks)}ê°œ ë¸”ë¡ ì„ íƒ ì™„ë£Œ! 'ë¶„ì„ ì‹¤í–‰' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
    else:
        st.warning("ë¶„ì„í•  ë¸”ë¡ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

with tab_run:
    st.header("ë¶„ì„ ì‹¤í–‰")
    has_basic_info = any([project_name, location, project_goals, additional_info])
    has_file = st.session_state.get('pdf_uploaded', False)
    has_existing_results = bool(st.session_state.get('analysis_results') or st.session_state.get('cot_results'))

    # ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê¸°ë³¸ ì •ë³´ ì²´í¬ ìŠ¤í‚µ (ì„¸ì…˜ ë³µì› ì‹œ)
    if not has_existing_results:
        if not has_basic_info and not has_file:
            st.warning("í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()

    selected_blocks = st.session_state.get('selected_blocks', [])
    if not selected_blocks and not has_existing_results:
        st.warning("ë¨¼ì € ë¶„ì„ ë¸”ë¡ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()

    # get_example_blocks()ëŠ” ì´ë¯¸ ëª¨ë“  ë¸”ë¡(custom í¬í•¨)ì„ ë°˜í™˜í•˜ë¯€ë¡œ ì¤‘ë³µ ë°©ì§€
    all_blocks = get_example_blocks()
    block_lookup = {
        block.get('id'): block
        for block in all_blocks
        if isinstance(block, dict) and block.get('id')
    }

    st.subheader("ë¶„ì„ ëŒ€ìƒ ì •ë³´")
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**í”„ë¡œì íŠ¸ ì •ë³´**")
        if project_name:
            st.write(f"â€¢ í”„ë¡œì íŠ¸ëª…: {project_name}")
        if location:
            st.write(f"â€¢ ìœ„ì¹˜/ì§€ì—­: {location}")
        if project_goals:
            ellipsis = "..." if len(project_goals) > 100 else ""
            st.write(f"â€¢ í”„ë¡œì íŠ¸ ëª©í‘œ: {project_goals[:100]}{ellipsis}")
        if additional_info:
            ellipsis = "..." if len(additional_info) > 100 else ""
            st.write(f"â€¢ ì¶”ê°€ ì •ë³´: {additional_info[:100]}{ellipsis}")

    with col2:
        st.markdown("**íŒŒì¼ ì •ë³´**")
        if has_file:
            file_analysis = st.session_state.get('file_analysis', {})
            file_name = "N/A"
            if st.session_state.get('uploaded_file'):
                file_name = st.session_state['uploaded_file'].name
            elif uploaded_file is not None:
                file_name = uploaded_file.name
            st.write(f"â€¢ íŒŒì¼ëª…: {file_name}")
            st.write(f"â€¢ íŒŒì¼ ìœ í˜•: {file_analysis.get('file_type', 'N/A')}")
            st.write(f"â€¢ í…ìŠ¤íŠ¸ ê¸¸ì´: {file_analysis.get('char_count', 0)}ì")
            st.write(f"â€¢ ë‹¨ì–´ ìˆ˜: {file_analysis.get('word_count', 0)}ë‹¨ì–´")
        else:
            st.write("â€¢ íŒŒì¼ ì—†ìŒ (ê¸°ë³¸ ì •ë³´ë§Œ ì‚¬ìš©)")
        reference_docs = st.session_state.get('reference_documents', [])
        if reference_docs:
            total_chars = sum(doc.get('char_count', 0) for doc in reference_docs)
            st.write(f"â€¢ ì°¸ê³  ìë£Œ: {len(reference_docs)}ê±´ ({total_chars:,}ì)")

    # ê³µê°„ ë°ì´í„° ì—°ë™ ìƒíƒœ í‘œì‹œ
    if st.session_state.get('block_spatial_data'):
        st.markdown("---")
        st.markdown("**ğŸ”— Mapping ë¸”ë¡ ì—°ë™ ë°ì´í„°**")
        block_spatial_data = st.session_state.block_spatial_data
        linked_blocks = [bid for bid in selected_blocks if bid in block_spatial_data]
        if linked_blocks:
            for block_id in linked_blocks:
                spatial_info = block_spatial_data[block_id]
                st.success(f"âœ“ {block_id}: {spatial_info['layer_name']} ({spatial_info['feature_count']}ê°œ í”¼ì²˜)")
        else:
            st.info(" Mapping í˜ì´ì§€ì—ì„œ ë¸”ë¡ì— ê³µê°„ ë°ì´í„°ë¥¼ ì—°ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.markdown("---")

    base_text_candidates: List[str] = []
    if has_file:
        base_text_candidates.append(st.session_state.get('pdf_text', ''))
    reference_combined = st.session_state.get('reference_combined_text', '')
    if reference_combined:
        base_text_candidates.append(reference_combined)
    base_text_candidates.extend(filter(None, [project_name, location, project_goals, additional_info]))
    base_text_source = "\n\n".join([text for text in base_text_candidates if text]).strip()

    analysis_text = base_text_source

    project_info_payload = {
        "project_name": project_name,
        "location": location,
        "project_goals": project_goals,
        "additional_info": additional_info,
        "file_text": analysis_text
    }
    reference_docs_meta = st.session_state.get('reference_documents', [])
    reference_combined_text = st.session_state.get('reference_combined_text', '')
    if reference_docs_meta:
        project_info_payload["reference_documents"] = reference_docs_meta
    if reference_combined_text:
        project_info_payload["reference_text"] = reference_combined_text

    # ë¬¸ì„œ ìš”ì•½ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
    if st.session_state.get('document_summary'):
        project_info_payload["document_summary"] = st.session_state.document_summary

    # ìœ„ì¹˜ ì¢Œí‘œ ì¶”ê°€ (Google Mapsìš©)
    if st.session_state.get('latitude') and st.session_state.get('longitude'):
        try:
            project_info_payload["latitude"] = float(st.session_state.latitude)
            project_info_payload["longitude"] = float(st.session_state.longitude)
        except (ValueError, TypeError):
            pass

    spatial_notice = None
    try:
        spatial_contexts = []

        # 1. ì—…ë¡œë“œëœ Shapefile ë ˆì´ì–´
        if st.session_state.get('geo_layers') and len(st.session_state.geo_layers) > 0:
            from geo_data_loader import extract_spatial_context_for_ai
            for layer_name, layer_data in st.session_state.geo_layers.items():
                gdf = layer_data['gdf']
                layer_type = 'general'
                if any(keyword in layer_name for keyword in ['í–‰ì •', 'ì‹œêµ°', 'ìë©´', 'ë²•ì •', 'adm']):
                    layer_type = 'administrative'
                elif any(keyword in layer_name for keyword in ['ê³µì‹œ', 'ê°€ê²©', 'ì§€ê°€', 'price']):
                    layer_type = 'land_price'
                elif any(keyword in layer_name for keyword in ['ì†Œìœ ', 'í† ì§€', 'owner']):
                    layer_type = 'ownership'
                spatial_text = extract_spatial_context_for_ai(gdf, layer_type)
                spatial_contexts.append(f"**ë ˆì´ì–´: {layer_name}**\n{spatial_text}")
        elif st.session_state.get('uploaded_gdf') is not None:
            from geo_data_loader import extract_spatial_context_for_ai
            gdf = st.session_state.uploaded_gdf
            layer_type = st.session_state.get('layer_type', 'general')
            spatial_text = extract_spatial_context_for_ai(gdf, layer_type)
            spatial_contexts.append(f"**ì—…ë¡œë“œ ë ˆì´ì–´**\n{spatial_text}")

        # WFS ë‹¤ìš´ë¡œë“œ ë°ì´í„°ëŠ” ë¸”ë¡ë³„ë¡œ ì„ íƒë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œì™¸
        # (ê° ë¸”ë¡ ì‹¤í–‰ ì‹œì ì— ì„ íƒí•œ ë ˆì´ì–´ê°€ feedbackìœ¼ë¡œ ì¶”ê°€ë¨)

        # 2. Mapping í˜ì´ì§€ì—ì„œ ë¸”ë¡ì— ì—°ë™ëœ ê³µê°„ ë°ì´í„°
        if st.session_state.get('block_spatial_data'):
            block_spatial_data = st.session_state.block_spatial_data
            for block_id in selected_blocks:
                if block_id in block_spatial_data:
                    spatial_info = block_spatial_data[block_id]
                    layer_name = spatial_info['layer_name']
                    feature_count = spatial_info['feature_count']

                    # GeoJSON ìš”ì•½ ì •ë³´ ì¶”ì¶œ
                    geojson = spatial_info.get('geojson', {})
                    features = geojson.get('features', [])

                    summary_text = f"**Mapping ì—°ë™ ë ˆì´ì–´: {layer_name}** (ë¸”ë¡: {block_id})\n"
                    summary_text += f"- ì´ í”¼ì²˜ ìˆ˜: {feature_count}ê°œ\n"

                    # ì†ì„±ë³„ ë¶„í¬ í†µê³„ ê³„ì‚° (ìš©ë„ì§€ì—­, ê±´ë¬¼ìš©ë„ ë“±)
                    if features:
                        from collections import Counter
                        # ìš©ë„ì§€ì—­/ê±´ë¬¼ìš©ë„ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
                        zone_counters = {}
                        price_values = []
                        area_values = []

                        for feature in features:
                            props = feature.get('properties', {})
                            for key, value in props.items():
                                if value is None or value == '':
                                    continue
                                key_upper = key.upper()
                                # ìš©ë„ì§€ì—­ ê´€ë ¨ ì»¬ëŸ¼
                                if any(k in key_upper for k in ['USG_NM', 'PRPOS_AREA_NM', 'ìš©ë„ì§€ì—­', 'ZONE_NM', 'JIJIMOK']):
                                    if 'ìš©ë„ì§€ì—­' not in zone_counters:
                                        zone_counters['ìš©ë„ì§€ì—­'] = Counter()
                                    zone_counters['ìš©ë„ì§€ì—­'][str(value)] += 1
                                # ê±´ë¬¼ìš©ë„ ê´€ë ¨ ì»¬ëŸ¼
                                elif any(k in key_upper for k in ['PURPS_NM', 'MAIN_PURPS', 'ì£¼ìš©ë„', 'BDTYP_NM']):
                                    if 'ê±´ë¬¼ìš©ë„' not in zone_counters:
                                        zone_counters['ê±´ë¬¼ìš©ë„'] = Counter()
                                    zone_counters['ê±´ë¬¼ìš©ë„'][str(value)] += 1
                                # ê³µì‹œì§€ê°€
                                elif any(k in key_upper for k in ['PBLNTF', 'ê³µì‹œì§€ê°€', 'PRICE']):
                                    try:
                                        price_values.append(float(value))
                                    except:
                                        pass
                                # ë©´ì 
                                elif any(k in key_upper for k in ['AREA', 'ë©´ì ', 'LNDPCLR']):
                                    try:
                                        area_values.append(float(value))
                                    except:
                                        pass

                        # ë¶„í¬ í†µê³„ í…ìŠ¤íŠ¸ ìƒì„±
                        for category, counter in zone_counters.items():
                            if counter:
                                summary_text += f"\n**{category} ë¶„í¬:**\n"
                                for zone_name, count in counter.most_common(10):
                                    summary_text += f"  - {zone_name}: {count}ê°œ\n"

                        # ê³µì‹œì§€ê°€ í†µê³„
                        if price_values:
                            avg_price = sum(price_values) / len(price_values)
                            summary_text += f"\n**ê³µì‹œì§€ê°€ í†µê³„:**\n"
                            summary_text += f"  - í‰ê· : {int(avg_price):,}ì›/ã¡\n"
                            summary_text += f"  - ìµœì†Œ: {int(min(price_values)):,}ì›/ã¡\n"
                            summary_text += f"  - ìµœëŒ€: {int(max(price_values)):,}ì›/ã¡\n"

                        # ë©´ì  í†µê³„
                        if area_values:
                            total_area = sum(area_values)
                            avg_area = total_area / len(area_values)
                            summary_text += f"\n**ë©´ì  í†µê³„:**\n"
                            summary_text += f"  - ì´ ë©´ì : {total_area:,.1f}ã¡\n"
                            summary_text += f"  - í‰ê·  ë©´ì : {avg_area:,.1f}ã¡\n"

                    spatial_contexts.append(summary_text)

        # ê³µê°„ ì»¨í…ìŠ¤íŠ¸ í†µí•© (ì—…ë¡œë“œëœ Shapefileë§Œ)
        if spatial_contexts:
            project_info_payload["spatial_data_context"] = "\n\n---\n\n".join(spatial_contexts)
            project_info_payload["has_geo_data"] = True
            spatial_notice = f"ğŸ“ {len(spatial_contexts)}ê°œ ê³µê°„ ë ˆì´ì–´ ì •ë³´ê°€ ë¶„ì„ì— í¬í•¨ë©ë‹ˆë‹¤."
        else:
            project_info_payload["has_geo_data"] = False
    except Exception as e:
        st.warning(f"ê³µê°„ ë°ì´í„° í†µí•© ì¤‘ ì˜¤ë¥˜: {e}")
        project_info_payload["has_geo_data"] = False
    if spatial_notice:
        st.caption(spatial_notice)

    # ë¶„ì„ ì„¸ì…˜ì´ ë¹„í™œì„±í™” ìƒíƒœì—ì„œë§Œ ë¸”ë¡ ë¶ˆì¼ì¹˜ ì‹œ ì´ˆê¸°í™”
    # (ë¶„ì„ ì¤‘ ë¸”ë¡ ì¶”ê°€ ì‹œì—ëŠ” ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ)
    if st.session_state.cot_plan and st.session_state.cot_plan != selected_blocks and not st.session_state.cot_session:
        reset_step_analysis_state()

    st.markdown("### ë‹¨ê³„ë³„ ë¶„ì„ ì œì–´")
    control_col1, control_col2 = st.columns(2)
    with control_col1:
        if st.button("ğŸ”„ ë¶„ì„ ì„¸ì…˜ ì´ˆê¸°í™”", use_container_width=True):
            print("[DEBUG] ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­ë¨")
            print(f"[DEBUG] ì´ˆê¸°í™” ì „ cot_results: {list(st.session_state.cot_results.keys())}")
            print(f"[DEBUG] ì´ˆê¸°í™” ì „ cot_current_index: {st.session_state.cot_current_index}")
            reset_step_analysis_state()
            print(f"[DEBUG] ì´ˆê¸°í™” í›„ cot_results: {list(st.session_state.cot_results.keys())}")
            print(f"[DEBUG] ì´ˆê¸°í™” í›„ cot_current_index: {st.session_state.cot_current_index}")
            st.success("ë¶„ì„ ì„¸ì…˜ì„ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    prepare_disabled = not analysis_text
    with control_col2:
        if st.button("ğŸš€ ë‹¨ê³„ë³„ ë¶„ì„ ì„¸ì…˜ ì¤€ë¹„", type="primary", use_container_width=True, disabled=prepare_disabled):
            if not analysis_text:
                st.warning("ë¶„ì„ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                try:
                    # ì„¸ì…˜ ì¤€ë¹„ ì‹œ ëª¨ë“  ì´ì „ ìƒíƒœë¥¼ ì™„ì „íˆ ì´ˆê¸°í™”
                    EnhancedArchAnalyzer.reset_lm()
                    st.session_state.pop('cot_analyzer', None)
                    st.session_state.pop('_last_analyzer_provider', None)
                    
                    # ì´ì „ ì„¸ì…˜ ì™„ì „íˆ ì œê±°
                    st.session_state.cot_session = None
                    st.session_state.cot_plan = []
                    st.session_state.cot_current_index = 0
                    st.session_state.cot_results = {}
                    st.session_state.cot_progress_messages = []
                    st.session_state.cot_history = []
                    st.session_state.cot_citations = {}
                    st.session_state.cot_feedback_inputs = {}
                    st.session_state.cot_running_block = None
                    st.session_state.skipped_blocks = []  # ê±´ë„ˆë›´ ë¸”ë¡ ëª©ë¡ ì´ˆê¸°í™”

                    analyzer = get_cot_analyzer()
                    if analyzer is None:
                        st.error("ë¶„ì„ê¸°ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                        st.stop()

                    # ë¬¸ì„œ ìš”ì•½ ìƒì„± (ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ê°€ ìˆê³ , ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš°)
                    if analysis_text and len(analysis_text) > 500 and not st.session_state.get('document_summary'):
                        with st.spinner("ğŸ“„ ë¬¸ì„œ ìš”ì•½ ìƒì„± ì¤‘..."):
                            summary_result = analyzer.generate_document_summary(analysis_text)
                            if summary_result.get('success'):
                                st.session_state.document_summary = summary_result
                                doc_type = summary_result.get('document_type', 'ë¯¸í™•ì¸')
                                key_topics_count = len(summary_result.get('key_topics', []))
                                st.info(f"âœ… ë¬¸ì„œ ìš”ì•½ ì™„ë£Œ: {doc_type} (í•µì‹¬ í‚¤ì›Œë“œ {key_topics_count}ê°œ ì¶”ì¶œ)")
                            else:
                                st.warning(f"ë¬¸ì„œ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {summary_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

                    # document_summaryë¥¼ project_info_payloadì— ì¶”ê°€
                    if st.session_state.get('document_summary'):
                        project_info_payload['document_summary'] = st.session_state.document_summary

                    # ì™„ì „íˆ ìƒˆë¡œìš´ ì„¸ì…˜ ìƒì„± (previous_resultsëŠ” ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì‹œì‘)
                    session = analyzer.initialize_cot_session(project_info_payload, analysis_text, len(selected_blocks))
                    # ì„¸ì…˜ì˜ previous_resultsê°€ ë¹ˆ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
                    if 'previous_results' in session:
                        session['previous_results'] = {}
                    if 'cot_history' in session:
                        session['cot_history'] = []
                    
                    st.session_state.cot_session = session
                    st.session_state.cot_plan = selected_blocks.copy()
                    st.session_state.cot_current_index = 0
                    st.session_state.cot_results = {}
                    st.session_state.cot_progress_messages = []
                    st.session_state.cot_history = []
                    st.session_state.analysis_results = {}
                    st.session_state.cot_citations = {}
                    st.session_state.cot_feedback_inputs = {}
                    st.success("ë‹¨ê³„ë³„ ë¶„ì„ ì„¸ì…˜ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆœì„œëŒ€ë¡œ ë¸”ë¡ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                    st.rerun()
                except Exception as e:
                    st.error(f"ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    active_plan = st.session_state.cot_plan if st.session_state.cot_session else selected_blocks

    # ë¶„ì„ ì¤‘ ë¸”ë¡ ì¶”ê°€ ê¸°ëŠ¥ (ë¶„ì„ ì‹¤í–‰ ì¤‘ì¼ ë•ŒëŠ” ì™„ì „íˆ ë¹„í™œì„±í™”)
    is_analysis_running = st.session_state.get('cot_running_block') is not None

    # ë¶„ì„ ì‹¤í–‰ ì¤‘ì—ëŠ” ë¸”ë¡ ì¶”ê°€ UIë¥¼ ì „í˜€ ë Œë”ë§í•˜ì§€ ì•ŠìŒ
    if not is_analysis_running and st.session_state.cot_session and st.session_state.cot_plan:
        with st.expander("â• ë¸”ë¡ ì¶”ê°€ (ë¶„ì„ ì§„í–‰ ì¤‘)", expanded=False):
            st.caption("ë¶„ì„ ì„¸ì…˜ì´ ì§„í–‰ ì¤‘ì¼ ë•Œ ìƒˆ ë¸”ë¡ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # í˜„ì¬ í”Œëœì— ì—†ëŠ” ë¸”ë¡ë“¤ë§Œ í‘œì‹œ
            current_plan_ids = set(st.session_state.cot_plan)
            available_to_add = [
                block for block in all_blocks
                if block.get('id') and block.get('id') not in current_plan_ids
            ]

            if available_to_add:
                # ë¸”ë¡ ì„ íƒ
                block_options = {block['id']: block.get('name', block['id']) for block in available_to_add}
                selected_block_to_add = st.selectbox(
                    "ì¶”ê°€í•  ë¸”ë¡ ì„ íƒ",
                    options=list(block_options.keys()),
                    format_func=lambda x: block_options.get(x, x),
                    key="add_block_selector"
                )

                # ì‚½ì… ìœ„ì¹˜ ì„ íƒ
                insert_positions = ["í˜„ì¬ ìœ„ì¹˜ (ë‹¤ìŒì— ì‹¤í–‰)", "í”Œëœ ë§ˆì§€ë§‰ì— ì¶”ê°€"]
                for i, plan_block_id in enumerate(st.session_state.cot_plan):
                    plan_block = block_lookup.get(plan_block_id, {})
                    plan_block_name = plan_block.get('name', plan_block_id)
                    insert_positions.append(f"{i+1}. {plan_block_name} ë’¤ì— ì‚½ì…")

                insert_position = st.selectbox(
                    "ì‚½ì… ìœ„ì¹˜",
                    options=insert_positions,
                    key="insert_position_selector"
                )

                if st.button("â• ë¸”ë¡ ì¶”ê°€", type="primary", key="add_block_btn"):
                    if selected_block_to_add:
                        print(f"[DEBUG ë¸”ë¡ì¶”ê°€] ì¶”ê°€ ì „ cot_plan: {st.session_state.cot_plan}")
                        print(f"[DEBUG ë¸”ë¡ì¶”ê°€] ì¶”ê°€í•  ë¸”ë¡: {selected_block_to_add}")
                        new_plan = st.session_state.cot_plan.copy()

                        adjust_index = False  # ì¸ë±ìŠ¤ ì¡°ì • í•„ìš” ì—¬ë¶€

                        if insert_position == "í˜„ì¬ ìœ„ì¹˜ (ë‹¤ìŒì— ì‹¤í–‰)":
                            # í˜„ì¬ ì¸ë±ìŠ¤ì— ì‚½ì…í•˜ê³ , ì¸ë±ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ (ìƒˆ ë¸”ë¡ì´ ë°”ë¡œ ë‹¤ìŒì— ì‹¤í–‰ë¨)
                            insert_idx = st.session_state.cot_current_index
                            adjust_index = False
                        elif insert_position == "í”Œëœ ë§ˆì§€ë§‰ì— ì¶”ê°€":
                            insert_idx = len(new_plan)
                            adjust_index = False
                        else:
                            # "N. ë¸”ë¡ëª… ë’¤ì— ì‚½ì…" í˜•ì‹ì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ
                            try:
                                position_num = int(insert_position.split(".")[0])
                                insert_idx = position_num  # í•´ë‹¹ ë¸”ë¡ ë’¤ì— ì‚½ì…
                                # í˜„ì¬ ì¸ë±ìŠ¤ë³´ë‹¤ ì•ì— ì‚½ì…ë˜ë©´ ì¸ë±ìŠ¤ ì¡°ì • í•„ìš”
                                adjust_index = (insert_idx <= st.session_state.cot_current_index)
                            except:
                                insert_idx = len(new_plan)
                                adjust_index = False

                        new_plan.insert(insert_idx, selected_block_to_add)
                        st.session_state.cot_plan = new_plan

                        # ì¸ë±ìŠ¤ ì¡°ì •
                        if adjust_index:
                            st.session_state.cot_current_index += 1

                        # selected_blocksë„ ì—…ë°ì´íŠ¸ (ì¼ê´€ì„± ìœ ì§€)
                        st.session_state.selected_blocks = new_plan.copy()

                        # ì„¸ì…˜ ì €ì¥ í›„ ì¬ì‹œì‘
                        try:
                            from auth.session_init import save_work_session
                            save_work_session()
                        except Exception as e:
                            print(f"ì„¸ì…˜ ì €ì¥ ì˜¤ë¥˜: {e}")

                        print(f"[DEBUG ë¸”ë¡ì¶”ê°€] ì¶”ê°€ í›„ cot_plan: {st.session_state.cot_plan}")
                        print(f"[DEBUG ë¸”ë¡ì¶”ê°€] ì¶”ê°€ í›„ selected_blocks: {st.session_state.selected_blocks}")
                        added_block = block_lookup.get(selected_block_to_add, {})
                        added_block_name = added_block.get('name', selected_block_to_add)
                        st.success(f"'{added_block_name}' ë¸”ë¡ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
            else:
                st.info("ì¶”ê°€ ê°€ëŠ¥í•œ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë¸”ë¡ì´ ì´ë¯¸ í”Œëœì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    st.markdown("### ë‹¨ê³„ ì§„í–‰ í˜„í™©")

    # DEBUG: ìƒíƒœ í™•ì¸ (ì½˜ì†”ì—ë§Œ ì¶œë ¥)
    print(f"[DEBUG] cot_session ì¡´ì¬: {st.session_state.cot_session is not None}")
    print(f"[DEBUG] cot_current_index: {st.session_state.cot_current_index}")
    print(f"[DEBUG] cot_results keys: {list(st.session_state.cot_results.keys())}")
    print(f"[DEBUG] cot_plan: {st.session_state.cot_plan}")
    if st.session_state.cot_session:
        print(f"[DEBUG] cot_session previous_results keys: {list(st.session_state.cot_session.get('previous_results', {}).keys())}")

    if not active_plan:
        st.info("ë¶„ì„ ì„¸ì…˜ì„ ì¤€ë¹„í•˜ë©´ ë‹¨ê³„ë³„ ì§„í–‰ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        running_block = st.session_state.get('cot_running_block')
        skipped_blocks = st.session_state.get('skipped_blocks', [])
        for idx, block_id in enumerate(active_plan, start=1):
            block = block_lookup.get(block_id)
            block_name = block.get('name', block_id) if block else block_id
            category = resolve_block_category(block) if block else "ê¸°íƒ€"

            # ê²°ê³¼ í™•ì¸ (cot_resultsì™€ analysis_results ë‘˜ ë‹¤ í™•ì¸)
            has_result = (block_id in st.session_state.cot_results or
                         block_id in st.session_state.analysis_results)

            # ìƒíƒœ ë°°ì§€ ê²°ì • (ìš°ì„ ìˆœìœ„: ì™„ë£Œ > ì§„í–‰ì¤‘ > ê±´ë„ˆëœ€ > ëŒ€ê¸° > ì¤€ë¹„)
            if has_result:
                # ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì™„ë£Œ (running_blockë³´ë‹¤ ìš°ì„ )
                status_badge = "âœ… ì™„ë£Œ"
            elif running_block == block_id:
                # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë¸”ë¡
                status_badge = "â³ ì§„í–‰ì¤‘"
            elif block_id in skipped_blocks:
                # ê±´ë„ˆë›´ ë¸”ë¡
                status_badge = "â­ï¸ ê±´ë„ˆëœ€"
            elif st.session_state.cot_session and idx == st.session_state.cot_current_index + 1:
                # ë‹¤ìŒ ì‹¤í–‰ ëŒ€ìƒ
                status_badge = "ğŸŸ¡ ëŒ€ê¸°"
            else:
                # ì¤€ë¹„ ìƒíƒœ
                status_badge = "âšª ì¤€ë¹„"
            is_collapsed = status_badge in ["âœ… ì™„ë£Œ", "â­ï¸ ê±´ë„ˆëœ€"]
            expander = st.expander(f"{idx}. {block_name} Â· {status_badge}", expanded=(not is_collapsed))
            with expander:
                st.caption((block.get('description') if block else "ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.") or "ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")

                # ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼: ì™„ë£Œëœ ë¸”ë¡ì´ë‚˜ ëŒ€ê¸°/ì¤€ë¹„ ìƒíƒœ ë¸”ë¡ì—ì„œ ì´ë™ ê°€ëŠ¥
                show_nav_button = False
                nav_button_label = ""

                if has_result:
                    # ì™„ë£Œëœ ë¸”ë¡: ì¬ì‹œì‘ ë²„íŠ¼
                    show_nav_button = True
                    nav_button_label = "ğŸ”„ ì´ ë¸”ë¡ë¶€í„° ì¬ì‹œì‘"
                elif st.session_state.cot_session and idx - 1 < st.session_state.cot_current_index:
                    # í˜„ì¬ ìœ„ì¹˜ë³´ë‹¤ ì´ì „ ë¸”ë¡: ëŒì•„ê°€ê¸° ë²„íŠ¼
                    show_nav_button = True
                    nav_button_label = "â¬…ï¸ ì´ ë¸”ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°"

                if show_nav_button:
                    col_nav, col_empty = st.columns([1, 2])
                    with col_nav:
                        if st.button(nav_button_label, key=f"nav_to_{block_id}", use_container_width=True):
                            # í˜„ì¬ ì¸ë±ìŠ¤ë¥¼ ì´ ë¸”ë¡ì˜ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
                            st.session_state.cot_current_index = idx - 1  # 0-based index
                            # ì´ ë¸”ë¡ê³¼ ì´í›„ ë¸”ë¡ì˜ ê²°ê³¼ ì‚­ì œ
                            blocks_to_remove = active_plan[idx - 1:]
                            for bid in blocks_to_remove:
                                if bid in st.session_state.cot_results:
                                    del st.session_state.cot_results[bid]
                                if bid in st.session_state.get('cot_citations', {}):
                                    del st.session_state.cot_citations[bid]
                            st.success(f"'{block_name}'(ìœ¼)ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.")
                            st.rerun()

                if has_result:
                    # í”¼ë“œë°± ìœ í˜• ì„ íƒ
                    from dspy_analyzer import FEEDBACK_TYPES
                    feedback_type_options = {
                        'auto': 'ìë™ ê°ì§€',
                        **{k: v['name'] for k, v in FEEDBACK_TYPES.items()}
                    }
                    feedback_type_key = f"feedback_type_{block_id}"
                    if feedback_type_key not in st.session_state:
                        st.session_state[feedback_type_key] = 'auto'

                    col_type, col_hint = st.columns([1, 2])
                    with col_type:
                        selected_feedback_type = st.selectbox(
                            "í”¼ë“œë°± ìœ í˜•",
                            options=list(feedback_type_options.keys()),
                            format_func=lambda x: feedback_type_options[x],
                            key=feedback_type_key,
                            help="í”¼ë“œë°± ìœ í˜•ì„ ì„ íƒí•˜ë©´ AIê°€ í•´ë‹¹ ê´€ì ì—ì„œ ì¬ë¶„ì„í•©ë‹ˆë‹¤."
                        )
                    with col_hint:
                        # ì„ íƒëœ ìœ í˜•ì— ëŒ€í•œ íŒíŠ¸ í‘œì‹œ
                        if selected_feedback_type != 'auto' and selected_feedback_type in FEEDBACK_TYPES:
                            hint_info = FEEDBACK_TYPES[selected_feedback_type]
                            st.caption(f"**{hint_info['description']}**")
                            st.caption(f"_{hint_info['hint']}_")

                    feedback_state_key = f"feedback_input_{block_id}"
                    if feedback_state_key not in st.session_state:
                        st.session_state[feedback_state_key] = st.session_state.cot_feedback_inputs.get(block_id, "")

                    # ìœ í˜•ë³„ placeholder ì„¤ì •
                    placeholder_text = "ì¬ë¶„ì„ ì‹œ ë°˜ì˜í•  ë©”ëª¨, ìˆ˜ì • ìš”ì²­, ì¶”ê°€ ì§€ì‹œì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”."
                    if selected_feedback_type != 'auto' and selected_feedback_type in FEEDBACK_TYPES:
                        placeholder_text = FEEDBACK_TYPES[selected_feedback_type]['hint']

                    feedback_text = st.text_area(
                        "í”¼ë“œë°± ì…ë ¥",
                        key=feedback_state_key,
                        height=120,
                        placeholder=placeholder_text
                    )
                    st.session_state.cot_feedback_inputs[block_id] = feedback_text
                    rerun_disabled = st.session_state.cot_running_block is not None or not feedback_text.strip()
                    if st.button(
                        "í”¼ë“œë°± ë°˜ì˜ ì¬ë¶„ì„",
                        key=f"rerun_btn_{block_id}",
                        disabled=rerun_disabled,
                        help="ì…ë ¥í•œ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ í•´ë‹¹ ë¸”ë¡ë§Œ ë‹¤ì‹œ ë¶„ì„í•©ë‹ˆë‹¤."
                    ):
                        analyzer = get_cot_analyzer()
                        st.session_state.cot_running_block = block_id
                        rerun_step_index = active_plan.index(block_id) + 1 if block_id in active_plan else None
                        progress_placeholder = st.empty()
                        rerun_block_info = block or {"id": block_id, "name": block_id}

                        def rerun_progress(message: str) -> None:
                            progress_placeholder.info(message)

                        # í”¼ë“œë°± ìœ í˜• ì „ë‹¬ (autoì´ë©´ None)
                        actual_feedback_type = None if selected_feedback_type == 'auto' else selected_feedback_type

                        try:
                            with st.spinner("í”¼ë“œë°± ê¸°ë°˜ ì¬ë¶„ì„ ì¤‘..."):
                                step_result = analyzer.run_cot_step(
                                    block_id,
                                    rerun_block_info,
                                    st.session_state.cot_session
                                    if st.session_state.cot_session
                                    else analyzer.initialize_cot_session(project_info_payload, analysis_text, len(active_plan)),
                                    progress_callback=rerun_progress,
                                    step_index=rerun_step_index,
                                    feedback=feedback_text.strip(),
                                    feedback_type=actual_feedback_type
                                )
                        finally:
                            st.session_state.cot_running_block = None

                        if step_result.get('success'):
                            st.session_state.cot_session = step_result['cot_session']
                            st.session_state.cot_results[block_id] = step_result['analysis']
                            analysis_result = step_result['analysis']
                            st.session_state.analysis_results[block_id] = analysis_result
                            # Citations ì €ì¥
                            if step_result.get('all_citations'):
                                st.session_state.cot_citations[block_id] = step_result['all_citations']
                            
                            # ìë™ ì €ì¥
                            project_info = {
                                "project_name": st.session_state.get('project_name', ''),
                                "location": st.session_state.get('location', '')
                            }
                            save_analysis_result(block_id, analysis_result, project_info)

                            # ë¶„ì„ ì§„í–‰ ìƒíƒœ ì‹¤ì‹œê°„ ì €ì¥
                            try:
                                from auth.session_init import save_analysis_progress
                                save_analysis_progress(force=True)
                            except Exception as e:
                                print(f"ë¶„ì„ ì§„í–‰ ì €ì¥ ì˜¤ë¥˜: {e}")

                            st.session_state.cot_history = step_result['cot_session'].get('cot_history', st.session_state.cot_history)
                            st.success(f"{block_name} ë¸”ë¡ì„ í”¼ë“œë°±ì— ë§ì¶° ì¬ë¶„ì„í–ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                        else:
                            st.error(f"ì¬ë¶„ì„ ì‹¤íŒ¨: {step_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                elif status_badge == "ğŸŸ¡ ëŒ€ê¸°":
                    st.info("ë‹¤ìŒ ì‹¤í–‰ ëŒ€ìƒ ë¸”ë¡ì…ë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¶„ì„ì„ ì§„í–‰í•˜ì„¸ìš”.")

    if st.session_state.cot_session and st.session_state.cot_current_index < len(st.session_state.cot_plan):
        # ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì¦ ë° ìë™ ì¡°ì •
        # í˜„ì¬ ì¸ë±ìŠ¤ ì•ì˜ ë¸”ë¡ë“¤ ì¤‘ ì™„ë£Œë˜ì§€ ì•Šì€ ë¸”ë¡ì´ ìˆëŠ”ì§€ í™•ì¸
        completed_blocks = set(st.session_state.cot_results.keys()) | set(st.session_state.analysis_results.keys())
        uncompleted_before_current = []
        for i in range(st.session_state.cot_current_index):
            bid = st.session_state.cot_plan[i]
            if bid not in completed_blocks and bid not in st.session_state.get('skipped_blocks', []):
                uncompleted_before_current.append((i, bid))

        # ì™„ë£Œë˜ì§€ ì•Šì€ ì´ì „ ë¸”ë¡ì´ ìˆìœ¼ë©´ ì¸ë±ìŠ¤ë¥¼ ì²« ë²ˆì§¸ ë¯¸ì™„ë£Œ ë¸”ë¡ìœ¼ë¡œ ì¡°ì •
        if uncompleted_before_current:
            first_uncompleted_idx, first_uncompleted_id = uncompleted_before_current[0]
            st.warning(f"âš ï¸ ì´ì „ ë¸”ë¡ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. {first_uncompleted_idx + 1}ë²ˆì§¸ ë¸”ë¡ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            st.session_state.cot_current_index = first_uncompleted_idx

        next_block_id = st.session_state.cot_plan[st.session_state.cot_current_index]
        next_block = block_lookup.get(next_block_id, {"id": next_block_id})
        next_block_name = next_block.get('name', next_block_id)

        # ë‹¤ìŒ ì‹¤í–‰ ëŒ€ìƒ ë¸”ë¡ ëª…í™•íˆ í‘œì‹œ
        st.info(f"ğŸ¯ ë‹¤ìŒ ì‹¤í–‰ ëŒ€ìƒ: **{st.session_state.cot_current_index + 1}ë²ˆì§¸ ë¸”ë¡ - {next_block_name}** (ID: `{next_block_id}`)")

        # ë¸”ë¡ë³„ ê³µê°„ ë°ì´í„° ì„ íƒ UI
        downloaded_geo_data = st.session_state.get('downloaded_geo_data', {})
        if downloaded_geo_data:
            with st.expander("ğŸ—ºï¸ ì´ ë¸”ë¡ì— ê³µê°„ ë°ì´í„° ì—°ê²°", expanded=False):
                st.caption("ë¶„ì„ì— í¬í•¨í•  WFS ë ˆì´ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

                # ë¸”ë¡ë³„ ì„ íƒ ìƒíƒœ ì´ˆê¸°í™”
                if 'block_spatial_selection' not in st.session_state:
                    st.session_state.block_spatial_selection = {}

                # í˜„ì¬ ë¸”ë¡ì˜ ì„ íƒ ìƒíƒœ
                current_selection = st.session_state.block_spatial_selection.get(next_block_id, [])

                # ë ˆì´ì–´ ì„ íƒ ì²´í¬ë°•ìŠ¤
                new_selection = []
                for layer_name, data in downloaded_geo_data.items():
                    is_checked = st.checkbox(
                        f"{layer_name} ({data['feature_count']}ê°œ)",
                        value=layer_name in current_selection,
                        key=f"spatial_block_{next_block_id}_{layer_name}"
                    )
                    if is_checked:
                        new_selection.append(layer_name)

                st.session_state.block_spatial_selection[next_block_id] = new_selection

                if new_selection:
                    st.success(f"ì„ íƒ: {len(new_selection)}ê°œ ë ˆì´ì–´")
                else:
                    st.info("ê³µê°„ ë°ì´í„° ì—†ì´ ë¶„ì„í•©ë‹ˆë‹¤.")

        # ì‹¤í–‰, ë©ˆì¶¤, ê±´ë„ˆë›°ê¸° ë²„íŠ¼
        is_running = st.session_state.cot_running_block is not None

        run_col, stop_col, skip_col = st.columns([3, 1, 1])
        with run_col:
            run_clicked = st.button(
                f"â–¶ï¸ {st.session_state.cot_current_index + 1}ë‹¨ê³„ ì‹¤í–‰: {next_block_name}",
                type="primary",
                disabled=is_running,
                use_container_width=True
            )
        with stop_col:
            stop_clicked = st.button(
                "â¹ï¸ ë©ˆì¶¤",
                disabled=not is_running,
                use_container_width=True,
                help="í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.",
                type="secondary"
            )
        with skip_col:
            skip_clicked = st.button(
                "â­ï¸ ê±´ë„ˆë›°ê¸°",
                disabled=is_running,
                use_container_width=True,
                help="ì´ ë¸”ë¡ì„ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ë¸”ë¡ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤."
            )
        
        # ë©ˆì¶¤ ì²˜ë¦¬
        if stop_clicked:
            st.session_state.cot_running_block = None
            st.warning(f"{next_block_name} ë¸”ë¡ ë¶„ì„ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
            
            # ì„¸ì…˜ ì €ì¥ í›„ ì¬ì‹œì‘
            try:
                from auth.session_init import save_work_session
                save_work_session()
            except Exception as e:
                print(f"ì„¸ì…˜ ì €ì¥ ì˜¤ë¥˜: {e}")
            
            st.rerun()

        # ê±´ë„ˆë›°ê¸° ì²˜ë¦¬
        if skip_clicked:
            # ê±´ë„ˆë›´ ë¸”ë¡ ê¸°ë¡ (ì„ íƒì )
            if 'skipped_blocks' not in st.session_state:
                st.session_state.skipped_blocks = []
            st.session_state.skipped_blocks.append(next_block_id)
            st.session_state.cot_current_index += 1
            
            # ì„¸ì…˜ ì €ì¥ í›„ ì¬ì‹œì‘
            try:
                from auth.session_init import save_work_session
                save_work_session()
            except Exception as e:
                print(f"ì„¸ì…˜ ì €ì¥ ì˜¤ë¥˜: {e}")
            
            st.info(f"{next_block_name} ë¸”ë¡ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()

        if run_clicked:
            analyzer = get_cot_analyzer()
            if analyzer is None:
                st.error("ë¶„ì„ê¸°ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                st.stop()
            progress_placeholder = st.empty()
            st.session_state.cot_running_block = next_block_id

            def step_progress(message: str) -> None:
                st.session_state.cot_progress_messages.append(message)
                if len(st.session_state.cot_progress_messages) > 50:
                    st.session_state.cot_progress_messages = st.session_state.cot_progress_messages[-50:]
                progress_placeholder.info(message)

            # ë¸”ë¡ë³„ ê³µê°„ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            block_spatial_context = ""
            block_spatial_selection = st.session_state.get('block_spatial_selection', {})
            selected_layers = block_spatial_selection.get(next_block_id, [])
            downloaded_geo_data = st.session_state.get('downloaded_geo_data', {})

            if selected_layers and downloaded_geo_data:
                try:
                    import geopandas as gpd
                    from geo_data_loader import extract_spatial_context_for_ai
                    spatial_parts = []
                    for layer_name in selected_layers:
                        if layer_name in downloaded_geo_data:
                            geo_data = downloaded_geo_data[layer_name]
                            geojson = geo_data.get('geojson', {})
                            features = geojson.get('features', [])
                            if features:
                                gdf = gpd.GeoDataFrame.from_features(features, crs='EPSG:4326')
                                # ë ˆì´ì–´ íƒ€ì… ì¶”ì •
                                layer_type = 'general'
                                if any(kw in layer_name for kw in ['í–‰ì •', 'ì‹œêµ°', 'ìë©´', 'ê²½ê³„']):
                                    layer_type = 'administrative'
                                elif any(kw in layer_name for kw in ['ìš©ë„', 'ì§€ì—­', 'ì§€êµ¬']):
                                    layer_type = 'zoning'
                                elif any(kw in layer_name for kw in ['ë„ì‹œê³„íš', 'ì‹œì„¤']):
                                    layer_type = 'urban_planning'
                                spatial_text = extract_spatial_context_for_ai(gdf, layer_type)
                                spatial_parts.append(f"**{layer_name}**\n{spatial_text}")
                    if spatial_parts:
                        block_spatial_context = "\n\n[ê³µê°„ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸]\n" + "\n\n---\n\n".join(spatial_parts)
                        st.caption(f"ğŸ“ {len(spatial_parts)}ê°œ ê³µê°„ ë ˆì´ì–´ í¬í•¨")
                except Exception as e:
                    st.warning(f"ê³µê°„ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

            # í”¼ë“œë°±ê³¼ ê³µê°„ ì»¨í…ìŠ¤íŠ¸ ê²°í•©
            user_feedback = st.session_state.cot_feedback_inputs.get(next_block_id, "").strip()
            combined_feedback = None
            if user_feedback or block_spatial_context:
                parts = []
                if user_feedback:
                    parts.append(user_feedback)
                if block_spatial_context:
                    parts.append(block_spatial_context)
                combined_feedback = "\n\n".join(parts) if parts else None

            try:
                with st.spinner("ë¶„ì„ ì‹¤í–‰ ì¤‘..."):
                    step_result = analyzer.run_cot_step(
                        next_block_id,
                        next_block,
                        st.session_state.cot_session,
                        progress_callback=step_progress,
                        step_index=st.session_state.cot_current_index + 1,
                        feedback=combined_feedback
                    )
            finally:
                st.session_state.cot_running_block = None

            if step_result.get('success'):
                st.session_state.cot_session = step_result['cot_session']
                st.session_state.cot_results[next_block_id] = step_result['analysis']
                analysis_result = step_result['analysis']
                st.session_state.analysis_results[next_block_id] = analysis_result
                
                # Citations ì €ì¥
                if step_result.get('all_citations'):
                    st.session_state.cot_citations[next_block_id] = step_result['all_citations']
                
                # ìë™ ì €ì¥
                project_info = {
                    "project_name": st.session_state.get('project_name', ''),
                    "location": st.session_state.get('location', '')
                }
                save_analysis_result(next_block_id, analysis_result, project_info)
                
                st.session_state.cot_history = step_result['cot_session'].get('cot_history', st.session_state.cot_history)
                st.session_state.cot_current_index += 1

                # ë¶„ì„ ì§„í–‰ ìƒíƒœ ì‹¤ì‹œê°„ ì €ì¥
                try:
                    from auth.session_init import save_analysis_progress, save_work_session
                    save_analysis_progress(force=True)  # ì¦‰ì‹œ ì €ì¥
                    save_work_session()
                except Exception as e:
                    print(f"ì„¸ì…˜ ì €ì¥ ì˜¤ë¥˜: {e}")

                st.success(f"{next_block_name} ë¸”ë¡ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
            else:
                st.error(f"{next_block_name} ë¸”ë¡ ë¶„ì„ ì‹¤íŒ¨: {step_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

    if st.session_state.cot_progress_messages:
        with st.expander("ìµœê·¼ ì§„í–‰ ë©”ì‹œì§€", expanded=False):
            for msg in st.session_state.cot_progress_messages[-10:]:
                st.write(msg)

    if st.session_state.cot_session and st.session_state.cot_plan and st.session_state.cot_current_index >= len(st.session_state.cot_plan):
        st.success("ëª¨ë“  ë¸”ë¡ì— ëŒ€í•œ ë‹¨ê³„ë³„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ê²°ê³¼ëŠ” cot_resultsì™€ analysis_results ë‘˜ ë‹¤ í™•ì¸ (ë™ê¸°í™” ë³´ì¥)
    analysis_results_state = st.session_state.get('analysis_results', {})
    cot_results_state = st.session_state.get('cot_results', {})

    # ë‘ ì €ì¥ì†Œë¥¼ ë³‘í•© (cot_resultsê°€ ìµœì‹ ì¼ ìˆ˜ ìˆìŒ)
    merged_results = {}
    for block_id in selected_blocks:
        if block_id in analysis_results_state:
            merged_results[block_id] = analysis_results_state[block_id]
        elif block_id in cot_results_state:
            # cot_resultsì—ë§Œ ìˆìœ¼ë©´ analysis_resultsì— ë³µì‚¬
            merged_results[block_id] = cot_results_state[block_id]
            st.session_state.analysis_results[block_id] = cot_results_state[block_id]

    if merged_results:
        ordered_results = merged_results
        if ordered_results:
            st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
            tab_blocks = list(ordered_results.keys())
            tab_titles = []
            for idx, block_id in enumerate(tab_blocks, start=1):
                block = block_lookup.get(block_id)
                block_name = block.get('name', block_id) if block else block_id
                tab_titles.append(f"{idx}. {block_name}")
            preview_tabs = st.tabs(tab_titles)
            for tab, block_id in zip(preview_tabs, tab_blocks):
                with tab:
                    block = block_lookup.get(block_id)
                    st.markdown("**ë¶„ì„ ê²°ê³¼**")
                    render_analysis_result(ordered_results[block_id])

    all_blocks_completed = (
        st.session_state.cot_plan
        and len(st.session_state.analysis_results) >= len(st.session_state.cot_plan)
    )
    if all_blocks_completed:
        if st.button("ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥", use_container_width=True):
            from datetime import datetime
            import json
            analysis_folder = "analysis_results"
            os.makedirs(analysis_folder, exist_ok=True)
            filename = f"analysis_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join(analysis_folder, filename)
            ordered_results_for_save = {
                block_id: st.session_state.analysis_results[block_id]
                for block_id in st.session_state.cot_plan
                if block_id in st.session_state.analysis_results
            }
            analysis_record = {
                "project_info": project_info_payload,
                "analysis_results": ordered_results_for_save,
                "analysis_timestamp": datetime.now().isoformat(),
                "cot_history": st.session_state.get('cot_history', []),
                "llm_settings": {
                    "temperature": st.session_state.llm_temperature,
                    "max_tokens": st.session_state.llm_max_tokens
                }
            }
            try:
                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(analysis_record, f, ensure_ascii=False, indent=2)
                st.success(f"ë¶„ì„ ê²°ê³¼ê°€ {filepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.warning(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

with tab_download:
    st.header("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")

    # cot_resultsì™€ analysis_results ë³‘í•© (ê°„í—ì  í‘œì‹œ ë¬¸ì œ ë°©ì§€)
    analysis_results = st.session_state.get('analysis_results', {}).copy()
    cot_results = st.session_state.get('cot_results', {})
    for block_id, result in cot_results.items():
        if block_id not in analysis_results:
            analysis_results[block_id] = result

    if not analysis_results:
        st.warning("ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    if analysis_results:
        st.success(f"{len(analysis_results)}ê°œ ë¶„ì„ ê²°ê³¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ AI ëª¨ë¸ ì •ë³´ í‘œì‹œ
        current_provider = get_current_provider()
        provider_config = PROVIDER_CONFIG.get(current_provider, {})
        provider_name = provider_config.get('display_name', current_provider)
        model_name = provider_config.get('model', 'unknown')
        st.caption(f"ğŸ¤– í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ AI ëª¨ë¸: {provider_name} ({model_name})")
        
        # Word ë¬¸ì„œ ìƒì„±
        if st.button("Word ë¬¸ì„œ ìƒì„±", type="primary"):
            with st.spinner("Word ë¬¸ì„œ ìƒì„± ì¤‘..."):
                doc = create_word_document(project_name, analysis_results)
                
                # ë©”ëª¨ë¦¬ì— ì§ì ‘ ë°”ì´íŠ¸ ë°ì´í„° ìƒì„±
                import io
                doc_buffer = io.BytesIO()
                doc.save(doc_buffer)
                doc_buffer.seek(0)
                file_data = doc_buffer.getvalue()
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
                st.download_button(
                    label="ğŸ“¥ Word ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ",
                    data=file_data,
                    file_name=f"{project_name}_ë¶„ì„ë³´ê³ ì„œ.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
        
        # ê°œë³„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        st.subheader("ê°œë³„ ë¶„ì„ ê²°ê³¼")
        for block_id, result in analysis_results.items():
            # ë¸”ë¡ ì´ë¦„ ì°¾ê¸°
            block_name = "ì•Œ ìˆ˜ ì—†ìŒ"
            example_blocks = get_example_blocks()
            custom_blocks = load_custom_blocks()
            for block in example_blocks + custom_blocks:
                if block['id'] == block_id:
                    block_name = block['name']
                    break
            
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f"**{block_name}**")
            with col2:
                st.download_button(
                    label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                    data=result,
                    file_name=f"{block_name}.txt",
                    mime="text/plain",
                    key=f"download_{block_id}"
                )
    else:
        st.info("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# í˜ì´ì§€ ë Œë”ë§ ì™„ë£Œ í›„ ì‘ì—… ì„¸ì…˜ ìë™ ì €ì¥
try:
    from auth.session_init import auto_save_trigger
    auto_save_trigger()
except Exception as e:
    pass
